{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f30ca-0c7a-4e9a-a5b8-ff293ef4851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(NOTEBOOK_DIR, '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e368ffd0-578b-474a-aeae-d75e83834bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import IPython\n",
    "from yargy.tokenizer import Tokenizer as YrgTokenizer\n",
    "from yargy.interpretation import fact as yrg_fact, attribute as yrg_attr\n",
    "from yargy.pipelines import morph_pipeline as yrg_morph_pipeline\n",
    "from yargy import rule as yrg_rule, or_ as yrg_r_or, and_ as yrg_r_and\n",
    "from yargy.predicates import \\\n",
    "    eq as yrg_rp_eq, gte as yrg_rp_gte, lte as yrg_rp_lte, type as yrg_rp_type, caseless as yrg_rp_caseless, \\\n",
    "    in_caseless as yrg_rp_in_caseless, custom as yrg_rp_custom, normalized as yrg_rp_normalized\n",
    "from yargy import Parser as YrgParser\n",
    "import razdel\n",
    "import navec\n",
    "import slovnet\n",
    "from ipymarkup import show_span_ascii_markup as natasha_show_markup\n",
    "import rdflib\n",
    "from tqdm import tqdm\n",
    "import pymorphy3\n",
    "\n",
    "from utils import dataset_utils\n",
    "from utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec58a56f-5637-4e6d-85a0-e174da718d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663c530-9dcf-4126-bbbb-b85faa2943db",
   "metadata": {},
   "source": [
    "# Search by word ontologies with Yargy parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd883-a975-4be6-bae8-6dbf2a182135",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cf9941-1940-4e1c-bc84-0333f1f4677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUESTS_FILE = \"../data/request_db.txt\"\n",
    "ADS_FILE = \"../data/ads_db.txt\"\n",
    "MATCHING_FILE = \"../data/matching_db.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f51ca95-b069-496f-8806-8716bc2e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ADS_FILE, encoding=\"utf-8\") as f:\n",
    "    ads_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56949b0-0bb4-40f3-a4df-37cee9ff1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(REQUESTS_FILE, encoding=\"utf-8\") as f:\n",
    "    requests_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357b3da0-cecd-4312-8bb8-d78563d1e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_markup = dataset_utils.load_matching_data(MATCHING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397f814-7690-447a-819a-d64a49dc317e",
   "metadata": {},
   "source": [
    "## Constructing Ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987674c-3b4e-4a8a-94a8-4f0785448288",
   "metadata": {},
   "source": [
    "### Service Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556804f0-b281-4d30-ba85-d54e1a46f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORPH_AN = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534de60e-4bb7-4431-9897-9c72bd524579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_letter_toks_to_value(size_letters, gender, max_x_count):\n",
    "\n",
    "    def lead_number_to_x(size_info, max_x_count):\n",
    "        first_digits = []\n",
    "        letters_started = False\n",
    "        end_letter_reached = False\n",
    "        res = []\n",
    "        for pos, c in enumerate(size_info):\n",
    "            if c.isdigit():\n",
    "                first_digits.append(c)\n",
    "                continue\n",
    "            if len(first_digits) > 0:\n",
    "                digit_val = max(1, min(int(\"\".join(first_digits)), max_x_count))\n",
    "                res = \"\".join([\"x\"] * digit_val)\n",
    "                if c.lower() != \"x\":\n",
    "                    res += size_info[pos:]\n",
    "                else:\n",
    "                    res += size_info[pos + 1:]\n",
    "            else:\n",
    "                res = size_info\n",
    "            break\n",
    "        return res.lower()\n",
    "\n",
    "    def letters_to_range(letters, gender_code):\n",
    "        m_letters_to_size_map = {\n",
    "            \"xs\": (40, 44),\n",
    "            \"s\": (42, 48),\n",
    "            \"m\": (44, 50),\n",
    "            \"l\": (48, 52),\n",
    "            \"xl\": (50, 56),\n",
    "            \"xxl\": (52, 60),\n",
    "            \"xxxl\": (54, 64),\n",
    "            \"xxxxl\": (56, 66),\n",
    "            \"xxxxxl\": (58, 70),\n",
    "            \"xxxxxxl\": (60, 72),\n",
    "            \"xxxxxxxl\": (62, 74),\n",
    "            \"xxxxxxxxl\": (64, 76),\n",
    "            \"xxxxxxxxxl\": (66, 78),\n",
    "            \"xxxxxxxxxxl\": (68, 80),\n",
    "        }\n",
    "        w_letters_to_size_map = {\n",
    "            \"xxxs\": (36, 36),\n",
    "            \"xxs\": (38, 38),\n",
    "            \"xs\": (38, 44),\n",
    "            \"s\": (42, 46),\n",
    "            \"m\": (44, 48),\n",
    "            \"l\": (46, 50),\n",
    "            \"xl\": (48, 54),\n",
    "            \"xxl\": (50, 58),\n",
    "            \"xxxl\": (52, 64),\n",
    "            \"xxxxl\": (54, 66),\n",
    "            \"xxxxxl\": (56, 70),\n",
    "            \"xxxxxxl\": (58, 74),\n",
    "            \"xxxxxxxl\": (56, 78),\n",
    "            \"xxxxxxxxl\": (58, 82),\n",
    "        }\n",
    "\n",
    "        if gender_code == \"m\":\n",
    "            mapper = m_letters_to_size_map\n",
    "        else:\n",
    "            mapper = w_letters_to_size_map\n",
    "\n",
    "        if letters not in mapper:\n",
    "            if letters[-1] == \"l\":\n",
    "                res_range = (max(max(v) for v in mapper.values()), MAX_CLOTHES_SIZE_INT)\n",
    "            else:\n",
    "                res_range = (MIN_CLOTHES_SIZE_INT, min(min(v) for v in mapper.values()))\n",
    "        else:\n",
    "            res_range = mapper[letters]\n",
    "\n",
    "        assert res_range[0] <= res_range[1]\n",
    "        return res_range\n",
    "\n",
    "    size_letters = lead_number_to_x(size_letters, max_x_count)\n",
    "\n",
    "    if gender is None or gender == ClothFact.Gender.UNISEX:\n",
    "        m_range = letters_to_range(size_letters, \"m\")\n",
    "        w_range = letters_to_range(size_letters, \"w\")\n",
    "        size_range = (min(m_range[0], w_range[0]), max(m_range[1], w_range[1]))\n",
    "    elif gender == ClothFact.Gender.MAN:\n",
    "        size_range = letters_to_range(size_letters, \"m\")\n",
    "    elif gender == ClothFact.Gender.WOMAN:\n",
    "        size_range = letters_to_range(size_letters, \"w\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gender name: {gender_name}\")\n",
    "\n",
    "    return size_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20dd48b9-30ed-416e-b366-18800b32d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClothFact:\n",
    "\n",
    "    class Gender:\n",
    "        MAN = 1\n",
    "        WOMAN = 2\n",
    "        UNISEX = 3\n",
    "\n",
    "    class Season:\n",
    "        DEMI_SEASON = 1\n",
    "        WINTER = 2\n",
    "        SUMMER = 3\n",
    "\n",
    "    def __init__(self, class_name, parsed_name, size_info, prop_dict):\n",
    "        self.class_name = class_name\n",
    "        self.parsed_name = parsed_name\n",
    "        self.size_info = size_info\n",
    "        self.props = prop_dict.copy()\n",
    "        self.parsed_size_info = None\n",
    "        self.decode_size_info()\n",
    "\n",
    "    def decode_size_info(self):\n",
    "    \n",
    "        def direct_info_to_range(fact, gender):\n",
    "    \n",
    "            def _number_toks_to_value(number_info):\n",
    "                if number_info.frac_part is not None:\n",
    "                    res = float(f\"{number_info.int_part}.{number_info.frac_part}\")\n",
    "                else:\n",
    "                    res = int(number_info.int_part)\n",
    "                return res\n",
    "    \n",
    "            size_info = fact.direct_values\n",
    "            info_type = size_info.__class__.__name__\n",
    "            if info_type == \"size_number_list\":\n",
    "                size_from = _number_toks_to_value(size_info.from_info)\n",
    "                if size_info.to_info is None:\n",
    "                    size_to = size_from\n",
    "                else:\n",
    "                    size_to = _number_toks_to_value(size_info.to_info)\n",
    "                size_range = (size_from, size_to)\n",
    "            elif info_type == \"size_letters_list\":\n",
    "                range_from = size_letter_toks_to_value(size_info.from_info.letters, gender, MAX_CLOTHES_SIZE_X_COUNT)\n",
    "                if size_info.to_info is None:\n",
    "                    range_to = range_from\n",
    "                else:\n",
    "                    range_to = size_letter_toks_to_value(size_info.to_info.letters, gender, MAX_CLOTHES_SIZE_X_COUNT)\n",
    "                size_range = (min(range_from), max(range_to))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown info type \\\"{info_type}\\\"\")\n",
    "    \n",
    "            return size_range\n",
    "    \n",
    "        def indirect_info_to_range(size_info, self):\n",
    "            if size_info.keyword == \"мальчик\":\n",
    "                self.props[\"gender\"] = ClothFact.Gender.MAN\n",
    "                size_range = (MIN_CHILD_CLOTHES_SIZE_INT, MAX_CHILD_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"девочка\":\n",
    "                self.props[\"gender\"] = ClothFact.Gender.WOMAN\n",
    "                size_range = (MIN_CHILD_CLOTHES_SIZE_INT, MAX_CHILD_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"мужчина\":\n",
    "                self.props[\"gender\"] = ClothFact.Gender.MAN\n",
    "                size_range = (MAX_CHILD_CLOTHES_SIZE_INT, MAX_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"женщина\":\n",
    "                self.props[\"gender\"] = ClothFact.Gender.WOMAN\n",
    "                size_range = (MAX_CHILD_CLOTHES_SIZE_INT, MAX_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"ребёнок\":\n",
    "                size_range = (MIN_CLOTHES_SIZE_INT, MAX_CHILD_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"взрослый\":\n",
    "                size_range = (MAX_CHILD_CLOTHES_SIZE_INT, MAX_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"школьник\":\n",
    "                # in some cases this word can also be applicable to women\n",
    "                if \"gender\" not in self.props or self.props[\"gender\"] is None:\n",
    "                    self.props[\"gender\"] = ClothFact.Gender.MAN\n",
    "                size_range = (MIN_M_SCHOOL_CLOTHES_SIZE_INT, MAX_M_SCHOOL_CLOTHES_SIZE_INT)\n",
    "            elif size_info.keyword == \"школьница\":\n",
    "                self.props[\"gender\"] = ClothFact.Gender.WOMAN\n",
    "                size_range = (MIN_W_SCHOOL_CLOTHES_SIZE_INT, MAX_W_SCHOOL_CLOTHES_SIZE_INT)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown keyword: {fact.size_info.keyword}\")\n",
    "    \n",
    "            if size_info.year_info_from_y is not None:\n",
    "                year_to_size_map = {\n",
    "                    0: (18, 26),\n",
    "                    1: (26, 28),\n",
    "                    2: (28, 30),\n",
    "                    3: (28, 30),\n",
    "                    4: (30, 30),\n",
    "                    5: (30, 32),\n",
    "                    6: (32, 34),\n",
    "                    7: (34, 36),\n",
    "                    8: (34, 36),\n",
    "                    9: (36, 36),\n",
    "                    10: (36, 36),\n",
    "                    11: (36, 38),\n",
    "                    12: (36, 38),\n",
    "                    13: (38, 40),\n",
    "                    14: (38, 40),\n",
    "                }\n",
    "                if size_info.year_info_to_y is None:\n",
    "                    size_info.year_info_to_y = size_info.year_info_from_y\n",
    "                from_y = int(size_info.year_info_from_y)\n",
    "                to_y = int(size_info.year_info_to_y)\n",
    "    \n",
    "                size_from = year_to_size_map.get(from_y, (MAX_CHILD_CLOTHES_SIZE_INT, size_range[1]))\n",
    "                size_to = year_to_size_map.get(to_y, (size_range[0], MAX_CLOTHES_SIZE_INT))\n",
    "                size_range = (min(size_from), max(size_to))\n",
    "            elif size_info.year_info_from_m is not None:\n",
    "                month_to_size_map = {\n",
    "                    0: (18, 18),\n",
    "                    1: (18, 20),\n",
    "                    2: (18, 20),\n",
    "                    3: (18, 22),\n",
    "                    4: (20, 22),\n",
    "                    5: (20, 22),\n",
    "                    6: (20, 24),\n",
    "                    7: (22, 24),\n",
    "                    8: (22, 24),\n",
    "                    9: (22, 26),\n",
    "                    10: (24, 26),\n",
    "                    11: (24, 26),\n",
    "                    12: (24, 26),\n",
    "                }\n",
    "                if size_info.year_info_to_m is None:\n",
    "                    size_info.year_info_to_m = size_info.year_info_from_m\n",
    "                from_m = int(size_info.year_info_from_m)\n",
    "                to_m = int(size_info.year_info_to_m)\n",
    "    \n",
    "                size_from = month_to_size_map.get(from_m, (MAX_CHILD_CLOTHES_SIZE_INT, size_range[1]))\n",
    "                size_to = month_to_size_map.get(to_m, (size_range[0], MAX_CLOTHES_SIZE_INT))\n",
    "                size_range = (min(size_from), max(size_to))\n",
    "            else:\n",
    "                # no info is present\n",
    "                pass\n",
    "    \n",
    "            return size_range\n",
    "\n",
    "        if self.size_info is None:\n",
    "            return\n",
    "\n",
    "        obj_class_name = self.size_info.__class__.__name__\n",
    "        if obj_class_name == \"size_info\":\n",
    "            if self.size_info.direct_values is not None:\n",
    "                size_range = direct_info_to_range(self.size_info.direct_values, self.props.get(\"gender\", None))\n",
    "            elif self.size_info.indirect_values is not None:\n",
    "                size_range = indirect_info_to_range(self.size_info.indirect_values, self)\n",
    "            else:\n",
    "                raise ValueError(\"Both size infos are None, while object itself is not\")\n",
    "        else:\n",
    "            raise ValueError(f\"No handler for object \\\"{obj_class_name}\\\"\")\n",
    "\n",
    "        if size_range[0] > size_range[1]:\n",
    "            size_range = (size_range[1], size_range[0])\n",
    "\n",
    "        self.parsed_size_info = size_range\n",
    "        assert isinstance(self.parsed_size_info, tuple) and len(self.parsed_size_info) == 2\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bd14f3-8438-4f1b-84d1-709cfd761c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_size_letters(token, max_x_count):\n",
    "    res = True\n",
    "    first_digits = []\n",
    "    letters_started = False\n",
    "    end_letter_reached = False\n",
    "    x_count = 0\n",
    "    for c in token:\n",
    "        if end_letter_reached:\n",
    "            res = False\n",
    "            break\n",
    "        if c.isdigit():\n",
    "            if letters_started:\n",
    "                res = False\n",
    "                break\n",
    "            first_digits.append(c)\n",
    "            continue\n",
    "        if not letters_started:\n",
    "            if len(first_digits) > 0:\n",
    "                if c.lower() != \"x\":\n",
    "                    res = False\n",
    "                    break\n",
    "                digit_val = int(\"\".join(first_digits))\n",
    "                if digit_val < 1 or digit_val > max_x_count:\n",
    "                    res = False\n",
    "                    break\n",
    "            if c.lower() not in [\"x\", \"s\", \"m\", \"l\"]:\n",
    "                res = False\n",
    "                break\n",
    "            if c.lower() in [\"s\", \"m\", \"l\"]:\n",
    "                end_letter_reached = True\n",
    "            first_digits = []\n",
    "            letters_started = True\n",
    "            continue\n",
    "        if c.lower() == \"x\":\n",
    "            x_count += 1\n",
    "            if len(first_digits) > 0 or x_count > max_x_count:\n",
    "                res = False\n",
    "                break\n",
    "            continue\n",
    "        if c.lower() not in [\"s\", \"m\", \"l\"]:\n",
    "            res = False\n",
    "            break\n",
    "        end_letter_reached = True\n",
    "    if not letters_started or not end_letter_reached:\n",
    "        res = False\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a5e2a98-722c-4315-9f94-f3d11a96caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ontology_stat(ont):\n",
    "    res = ont.query(\n",
    "        \"SELECT DISTINCT ?main_obj \"\n",
    "        \"WHERE { \"\n",
    "        \"    ?main_obj local:is_included local:parsed_objects . \"\n",
    "        \"    FILTER (NOT EXISTS {?main_obj local:is_subclass ?parent_obj .}) \"\n",
    "        \"}\"\n",
    "    )\n",
    "    obj_root_name_list = [row[0].n3(ont.namespace_manager) for row in res]\n",
    "    all_obj_name_set = set()\n",
    "    for root_obj_name in obj_root_name_list:\n",
    "        res = ontology_g.query(\n",
    "            \"SELECT DISTINCT ?name \"\n",
    "            \"WHERE { \"\n",
    "            f\"    {root_obj_name} local:has_name ?name . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        all_obj_name_set |= set(row[0].toPython() for row in res)\n",
    "        res = ontology_g.query(\n",
    "            \"SELECT DISTINCT ?name \"\n",
    "            \"WHERE { \"\n",
    "            \"    ?main_obj local:is_included local:parsed_objects . \"\n",
    "            f\"    ?main_obj local:is_subclass+ {root_obj_name} . \"\n",
    "            \"    ?main_obj local:has_name ?name . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        all_obj_name_set |= set(row[0].toPython() for row in res)\n",
    "\n",
    "    name_obj_map = {}\n",
    "    for obj_name in all_obj_name_set:\n",
    "        res = ont.query(\n",
    "            \"SELECT ?main_obj \"\n",
    "            \"WHERE { \"\n",
    "            \"    ?main_obj local:is_included local:parsed_objects . \"\n",
    "            f\"    ?main_obj local:has_name \\\"{obj_name}\\\" . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        out_list = [row[0].n3(ont.namespace_manager) for row in res]\n",
    "        name_obj_map[obj_name] = out_list\n",
    "\n",
    "    res = ont.query(\n",
    "        \"SELECT DISTINCT ?main_obj \"\n",
    "        \"WHERE { \"\n",
    "        \"    ?main_obj local:is_included local:parsed_attributes . \"\n",
    "        \"    FILTER (NOT EXISTS {?main_obj local:is_subclass ?parent_obj .}) \"\n",
    "        \"}\"\n",
    "    )\n",
    "    attr_root_name_list = [row[0].n3(ont.namespace_manager) for row in res]\n",
    "    all_attr_name_set = set()\n",
    "    for root_attr_name in attr_root_name_list:\n",
    "        res = ontology_g.query(\n",
    "            \"SELECT DISTINCT ?name \"\n",
    "            \"WHERE { \"\n",
    "            f\"    {root_attr_name} local:has_name ?name . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        all_attr_name_set |= set(row[0].toPython() for row in res)\n",
    "        res = ontology_g.query(\n",
    "            \"SELECT DISTINCT ?name \"\n",
    "            \"WHERE { \"\n",
    "            \"    ?main_obj local:is_included local:parsed_attributes . \"\n",
    "            f\"    ?main_obj local:is_subclass+ {root_attr_name} . \"\n",
    "            \"    ?main_obj local:has_name ?name . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        all_attr_name_set |= set(row[0].toPython() for row in res)\n",
    "\n",
    "    name_attr_map = {}\n",
    "    for attr_name in all_attr_name_set:\n",
    "        res = ont.query(\n",
    "            \"SELECT ?main_obj \"\n",
    "            \"WHERE { \"\n",
    "            \"    ?main_obj local:is_included local:parsed_attributes . \"\n",
    "            f\"    ?main_obj local:has_name \\\"{attr_name}\\\" . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        out_list = [row[0].n3(ont.namespace_manager) for row in res]\n",
    "        assert len(out_list) == 1\n",
    "        name_attr_map[attr_name] = out_list[0]\n",
    "\n",
    "    return {\n",
    "        \"obj_name_set\": all_obj_name_set,\n",
    "        \"name_obj_map\": name_obj_map,\n",
    "        \"attr_name_set\": all_attr_name_set,\n",
    "        \"name_attr_map\": name_attr_map,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2049f09-ee2a-4984-b15f-c7b454618789",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLOTHES_SIZE_INT = 18\n",
    "MAX_CLOTHES_SIZE_INT = 82\n",
    "MIN_CHILD_CLOTHES_SIZE_INT = MIN_CLOTHES_SIZE_INT\n",
    "MAX_CHILD_CLOTHES_SIZE_INT = 43\n",
    "MIN_W_SCHOOL_CLOTHES_SIZE_INT = 26\n",
    "MAX_W_SCHOOL_CLOTHES_SIZE_INT = 48\n",
    "MIN_M_SCHOOL_CLOTHES_SIZE_INT = 28\n",
    "MAX_M_SCHOOL_CLOTHES_SIZE_INT = 50\n",
    "MAX_CLOTHES_SIZE_X_COUNT = 12\n",
    "\n",
    "# === indirect size and gender information ===\n",
    "\n",
    "o_size_indirect_info = yrg_fact(\n",
    "    \"size_indirect_info\", [\"keyword\", \"year_info_from_y\", \"year_info_from_m\", \"year_info_to_y\", \"year_info_to_m\"]\n",
    ")\n",
    "r_size_gender_indirect_info = yrg_rule(\n",
    "    yrg_r_or(\n",
    "        yrg_rp_caseless(\"на\"),\n",
    "        yrg_rp_caseless(\"для\"),\n",
    "    ).optional(),\n",
    "    yrg_morph_pipeline([\n",
    "        \"мальчик\",\n",
    "        \"девочка\",\n",
    "        \"мужчина\",\n",
    "        \"женщина\",\n",
    "        \"ребёнок\",\n",
    "        \"взрослый\",\n",
    "        \"школьник\",\n",
    "        \"школьница\",\n",
    "    ]).interpretation(o_size_indirect_info.keyword.normalized()),\n",
    ")\n",
    "r_size_year_info = yrg_r_or(\n",
    "    yrg_rule(\n",
    "        yrg_rp_type(\"INT\").interpretation(o_size_indirect_info.year_info_from_y),\n",
    "        yrg_rule(\n",
    "            yrg_rp_eq(\"-\"),\n",
    "            yrg_rp_type(\"INT\").interpretation(o_size_indirect_info.year_info_to_y)\n",
    "        ).optional(),\n",
    "        yrg_morph_pipeline([\"лет\", \"год\"]),\n",
    "    ),\n",
    "    yrg_rule(\n",
    "        yrg_rp_type(\"INT\").interpretation(o_size_indirect_info.year_info_from_m),\n",
    "        yrg_rule(\n",
    "            yrg_rp_eq(\"-\"),\n",
    "            yrg_rp_type(\"INT\").interpretation(o_size_indirect_info.year_info_to_m)\n",
    "        ).optional(),\n",
    "        yrg_morph_pipeline([\"месяц\", \"мес\"]),\n",
    "    ),\n",
    ").interpretation(o_size_indirect_info)\n",
    "r_size_year_gender_indirect_info = yrg_rule(\n",
    "    r_size_gender_indirect_info,\n",
    "    r_size_year_info.optional(),\n",
    ").interpretation(o_size_indirect_info)\n",
    "\n",
    "# === direct size and gender information ===\n",
    "\n",
    "o_size_number = yrg_fact(\"size_number\", [\"int_part\", \"frac_part\"])\n",
    "r_size_number = yrg_rule(\n",
    "    yrg_r_and(\n",
    "        yrg_rp_gte(MIN_CLOTHES_SIZE_INT),\n",
    "        yrg_rp_lte(MAX_CLOTHES_SIZE_INT),\n",
    "    ).interpretation(o_size_number.int_part),\n",
    "    yrg_r_or(\n",
    "        yrg_rule(\n",
    "            yrg_rp_eq(\".\"),\n",
    "            yrg_rp_type(\"INT\").interpretation(o_size_number.frac_part),\n",
    "        ),\n",
    "        yrg_rule(\n",
    "            yrg_rp_caseless(\"с\"),\n",
    "            yrg_rp_caseless(\"половиной\")\n",
    "        ).interpretation(o_size_number.frac_part.const(\"5\")),\n",
    "    ).optional(),\n",
    ").interpretation(o_size_number)\n",
    "o_size_number_list = yrg_fact(\"size_number_list\", [\"from_info\", \"to_info\"])\n",
    "r_size_number_list = yrg_rule(\n",
    "    r_size_number.interpretation(o_size_number_list.from_info),\n",
    "    yrg_rule(\n",
    "        yrg_rp_eq(\"-\"),  # all types of dashes are converted to \"-\" on preprocessing\n",
    "        r_size_number.interpretation(o_size_number_list.to_info),\n",
    "    ).optional(),\n",
    ").interpretation(o_size_number_list)\n",
    "\n",
    "o_size_letters = yrg_fact(\"size_letters\", [\"letters\"])\n",
    "r_size_letters = yrg_rule(\n",
    "    yrg_r_and(   # tokenizer splits numbers from letters, so 10XL becomes '10', 'XL'\n",
    "        yrg_rp_gte(2),\n",
    "        yrg_rp_lte(MAX_CLOTHES_SIZE_X_COUNT),\n",
    "    ).optional(),\n",
    "    yrg_rp_custom(lambda tok: is_size_letters(tok, MAX_CLOTHES_SIZE_X_COUNT)),\n",
    ").interpretation(o_size_letters.letters).interpretation(o_size_letters)\n",
    "o_size_letters_list = yrg_fact(\"size_letters_list\", [\"from_info\", \"to_info\"])\n",
    "r_size_letters_list = yrg_rule(\n",
    "    r_size_letters.interpretation(o_size_letters_list.from_info),\n",
    "    yrg_rule(\n",
    "        yrg_rp_eq(\"-\"),  # all types of dashes are converted to \"-\" on preprocessing\n",
    "        r_size_letters.interpretation(o_size_letters_list.to_info),\n",
    "    ).optional(),\n",
    ").interpretation(o_size_letters_list)\n",
    "\n",
    "n_size_word = yrg_r_or(\n",
    "    yrg_rule(yrg_rp_normalized(\"размер\")),\n",
    "    yrg_rule(\n",
    "        yrg_rp_caseless(\"р\"),\n",
    "        yrg_rp_eq(\".\").optional()\n",
    "    ),\n",
    ")\n",
    "o_size_direct_values = yrg_fact(\"size_direct_values\", [\"direct_values\"])\n",
    "r_size_direct_values = yrg_r_or(\n",
    "    yrg_rule(\n",
    "        n_size_word.optional(),\n",
    "        yrg_r_or(\n",
    "            r_size_number_list,\n",
    "            r_size_letters_list,\n",
    "        ).interpretation(o_size_direct_values.direct_values),\n",
    "        n_size_word.optional(),\n",
    "    ),\n",
    "    yrg_rule(\n",
    "        r_size_number_list,\n",
    "        n_size_word,\n",
    "    ).interpretation(o_size_direct_values.direct_values),\n",
    ").interpretation(o_size_direct_values)\n",
    "\n",
    "# === general size information ===\n",
    "\n",
    "o_size_info = yrg_fact(\"size_info\", [\"direct_values\", \"indirect_values\"])\n",
    "r_size_info = yrg_r_or(\n",
    "    r_size_year_gender_indirect_info.interpretation(o_size_info.indirect_values),\n",
    "    r_size_direct_values.interpretation(o_size_info.direct_values),\n",
    ").interpretation(o_size_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16d00f-a595-43d0-a976-54bdd6e6ad1a",
   "metadata": {},
   "source": [
    "### Clothes Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d10bf2c-7860-46b1-afed-f648ed075682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na62fcf472563469fb3ac2dc4191af632 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology_g = rdflib.Graph()\n",
    "ontology_g.parse(source=\"search_pipeline/ontology.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fe6b5d-5b3e-4c67-8493-5e0a148b9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_stat = calc_ontology_stat(ontology_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31af485-9dd6-4975-8442-324918d99f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_and_split_by_sentence(text):\n",
    "    s_toks = []\n",
    "    for sentence in razdel.sentenize(text):\n",
    "        s_toks.append(list(tok.text for tok in razdel.tokenize(sentence.text)))\n",
    "\n",
    "    all_toks = []\n",
    "    sentence_ranges = []\n",
    "    sent_offset = 0\n",
    "    for toks in s_toks:\n",
    "        all_toks += toks\n",
    "        sentence_ranges.append((sent_offset, sent_offset + len(toks)))\n",
    "        sent_offset += len(toks)\n",
    "\n",
    "    return all_toks, sentence_ranges\n",
    "\n",
    "\n",
    "def _get_relation(ont, name1, name2, is_attr):\n",
    "    if name1 == name2:\n",
    "        return 0\n",
    "    parsed_class_str = \"local:parsed_objects\" if not is_attr else \"local:parsed_attributes\"\n",
    "    res = ont.query(\n",
    "        \"SELECT DISTINCT ?main_obj \"\n",
    "        \"WHERE { \"\n",
    "        \"    ?main_obj local:is_subclass+ ?parent_obj .\"\n",
    "        f\"    ?main_obj local:is_included {parsed_class_str} . \"\n",
    "        f\"    ?parent_obj local:is_included {parsed_class_str} . \"\n",
    "        f\"    ?parent_obj local:has_name \\\"{name1}\\\" . \"\n",
    "        f\"    ?main_obj local:has_name \\\"{name2}\\\" . \"\n",
    "        \"}\"\n",
    "    )\n",
    "    if len(res) > 0:\n",
    "        return 1\n",
    "    res = ont.query(\n",
    "        \"SELECT DISTINCT ?main_obj \"\n",
    "        \"WHERE { \"\n",
    "        \"    ?main_obj local:is_subclass+ ?parent_obj .\"\n",
    "        f\"    ?main_obj local:is_included {parsed_class_str} . \"\n",
    "        f\"    ?parent_obj local:is_included {parsed_class_str} . \"\n",
    "        f\"    ?parent_obj local:has_name \\\"{name2}\\\" . \"\n",
    "        f\"    ?main_obj local:has_name \\\"{name1}\\\" . \"\n",
    "        \"}\"\n",
    "    )\n",
    "    if len(res) > 0:\n",
    "        return -1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _get_all_word_relations(text, ont, ont_stat, morph_an, size_rule):\n",
    "    SEPARATOR_TOKS = [\",\", \";\", \":\", \"и\", \"с\", \"со\", \"+\"]\n",
    "\n",
    "    toks, sentence_ranges = _tokenize_and_split_by_sentence(text)\n",
    "    relation_list = []\n",
    "\n",
    "    for tok_idx, tok in enumerate(toks):\n",
    "        if tok in SEPARATOR_TOKS:\n",
    "            relation_list.append({\"rel\": \"syntax:sep\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "    \n",
    "    size_parser = YrgParser(size_rule)\n",
    "    matches = size_parser.findall(text)\n",
    "    for m in matches:\n",
    "        pos = 0\n",
    "        is_size_found = False\n",
    "        tok_idx = 0\n",
    "        while tok_idx < len(toks):\n",
    "            tok = toks[tok_idx]\n",
    "            pos = text.find(tok, pos)\n",
    "            assert pos >= 0\n",
    "            if (pos >= m.span.start and pos < m.span.stop) or (pos + len(tok) >= m.span.stop and not is_size_found):\n",
    "                relation_list.append({\"rel\": \"ont:size\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "                is_size_found = True\n",
    "            else:\n",
    "                if is_size_found:\n",
    "                    # workaround for size ranges, because rule always selects shortest match span and ranges like \"80-90\" become \"80\"\n",
    "                    if tok == \"-\":\n",
    "                        relation_list.append({\"rel\": \"ont:size\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "                        tok_idx += 1\n",
    "                        if tok_idx < len(toks) and toks[tok_idx].isdigit():\n",
    "                            relation_list.append({\"rel\": \"ont:size\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "                            tok_idx += 1\n",
    "                    break\n",
    "            tok_idx += 1\n",
    "        assert is_size_found\n",
    "\n",
    "    normed_toks = [morph_an.parse(tok)[0].normal_form for tok in toks]\n",
    "    obj_toks = [(idx, tok) for idx, tok in enumerate(normed_toks) if tok in ont_stat[\"obj_name_set\"]]\n",
    "    for (tok_idx, tok) in obj_toks:\n",
    "        relation_list.append({\"rel\": f\"ont:obj:{ont_stat['name_obj_map'][tok][0]}\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "        for (dep_tok_idx, dep_tok) in obj_toks:\n",
    "            if dep_tok == tok:\n",
    "                continue\n",
    "            dep_code = _get_relation(ont, tok, dep_tok, is_attr=False)\n",
    "            if dep_code is None:\n",
    "                continue\n",
    "            elif dep_code == 1:\n",
    "                relation_list.append({\"rel\": \"ont:rel:obj_inst\", \"from\": tok_idx, \"to\": dep_tok_idx})\n",
    "            elif dep_code == -1:\n",
    "                relation_list.append({\"rel\": \"ont:rel:obj_inst\", \"from\": dep_tok_idx, \"to\": tok_idx})\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dependency: {dep_code} for {tok} and {dep_tok}\")\n",
    "\n",
    "    attr_toks = [(idx, tok) for idx, tok in enumerate(normed_toks) if tok in ont_stat[\"attr_name_set\"]]\n",
    "    for (tok_idx, tok) in attr_toks:\n",
    "        relation_list.append({\"rel\": f\"ont:attr:{ont_stat['name_attr_map'][tok]}\", \"from\": tok_idx, \"to\": tok_idx})\n",
    "        for (dep_tok_idx, dep_tok) in obj_toks:\n",
    "            if dep_tok == tok:\n",
    "                continue\n",
    "            dep_code = _get_relation(ont, tok, dep_tok, is_attr=True)\n",
    "            if dep_code is None:\n",
    "                continue\n",
    "            elif dep_code == 1:\n",
    "                relation_list.append({\"rel\": \"ont:rel:attr_inst\", \"from\": tok_idx, \"to\": dep_tok_idx})\n",
    "            elif dep_code == -1:\n",
    "                relation_list.append({\"rel\": \"ont:rel:attr_inst\", \"from\": dep_tok_idx, \"to\": tok_idx})\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dependency: {dep_code} for {tok} and {dep_tok}\")\n",
    "\n",
    "    return relation_list, toks, sentence_ranges\n",
    "\n",
    "\n",
    "def extract_facts(text, ont, ont_stat, morph_an, size_rule):\n",
    "\n",
    "    def _infer_macro_relations(rel_list, sentence_ranges):\n",
    "        macro_rels = []\n",
    "\n",
    "        # same sentence\n",
    "        for sent_range in sentence_ranges:\n",
    "            sent_idx_list = list(range(sent_range[0], sent_range[1]))\n",
    "            size_info_cnt = 0\n",
    "            obj_cnt = 0\n",
    "            tok_type = None\n",
    "            first_type = None\n",
    "            last_size_info_idx = -1\n",
    "            for idx in sent_idx_list:\n",
    "                idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "                if \"ont:size\" in idx_rels:\n",
    "                    if tok_type != 'size':  # size info can contain multiple tokens\n",
    "                        size_info_cnt += 1\n",
    "                    tok_type = 'size'\n",
    "                    last_size_info_idx = idx\n",
    "                elif any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                    obj_cnt += 1  # object is identified by single token\n",
    "                    tok_type = 'obj'\n",
    "                else:\n",
    "                    tok_type = None\n",
    "                if first_type is None and tok_type is not None:\n",
    "                    first_type = tok_type\n",
    "\n",
    "            if obj_cnt > 0:\n",
    "                obj_tok_idx_list = sorted(\n",
    "                    [rel[\"to\"] for rel in rel_list if rel[\"rel\"].startswith(\"ont:obj:\") and rel[\"to\"] in sent_idx_list]\n",
    "                )\n",
    "                if obj_cnt == 1:\n",
    "                    assert len(obj_tok_idx_list) == 1\n",
    "                    obj_tok_idx = obj_tok_idx_list[0]\n",
    "                    for tok_idx in sent_idx_list:\n",
    "                        idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                        if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                            macro_rels.append({\"rel\": \"prop\", \"from\": tok_idx, \"to\": obj_tok_idx})\n",
    "                else:\n",
    "                    for tok_idx in range(obj_tok_idx_list[0]):\n",
    "                        idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                        if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                            macro_rels.append({\"rel\": \"prop\", \"from\": tok_idx, \"to\": obj_tok_idx_list[0]})\n",
    "                    for idx_idx in range(1, len(obj_tok_idx_list)):\n",
    "                        sep_idx_list = []\n",
    "                        for tok_idx in range(obj_tok_idx_list[idx_idx - 1] + 1, obj_tok_idx_list[idx_idx]):\n",
    "                            idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                            if \"syntax:sep\" in idx_rels:\n",
    "                                sep_idx_list.append(tok_idx)\n",
    "                        if len(sep_idx_list) == 0:\n",
    "                            sep_idx_list = [obj_tok_idx_list[idx_idx - 1]]\n",
    "                        if len(sep_idx_list) > 1:\n",
    "                            sep_idx_list = [obj_tok_idx_list[idx_idx - 1]]\n",
    "\n",
    "                        for tok_idx in range(obj_tok_idx_list[idx_idx - 1] + 1, sep_idx_list[0]):\n",
    "                            idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                            if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                                macro_rels.append({\"rel\": \"prop\", \"from\": tok_idx, \"to\": obj_tok_idx_list[idx_idx - 1]})\n",
    "                        for tok_idx in range(sep_idx_list[0] + 1, obj_tok_idx_list[idx_idx]):\n",
    "                            idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                            if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                                macro_rels.append({\"rel\": \"prop\", \"from\": tok_idx, \"to\": obj_tok_idx_list[idx_idx]})\n",
    "                    for tok_idx in range(obj_tok_idx_list[-1] + 1, sent_idx_list[-1]):\n",
    "                        idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                        if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                            macro_rels.append({\"rel\": \"prop\", \"from\": tok_idx, \"to\": obj_tok_idx_list[-1]})\n",
    "\n",
    "            if size_info_cnt > 0 and obj_cnt > 0:\n",
    "                last_size_info_start_idx = None\n",
    "                last_assign_tok_idx = 0\n",
    "                is_size_info_continues = False\n",
    "                if first_type == 'obj':\n",
    "                    for idx_idx, idx in enumerate(sent_idx_list):\n",
    "                        idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "                        if \"ont:size\" in idx_rels:\n",
    "                            if not is_size_info_continues:\n",
    "                                last_size_info_start_idx = idx\n",
    "                            for obj_idx in sent_idx_list[last_assign_tok_idx:idx_idx]:\n",
    "                                obj_idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == obj_idx]\n",
    "                                if any(rel.startswith(\"ont:obj:\") for rel in obj_idx_rels):  # any() returns False on empty input\n",
    "                                    macro_rels.append({\"rel\": \"size\", \"from\": idx, \"to\": obj_idx})\n",
    "                            is_size_info_continues = True\n",
    "                        else:\n",
    "                            if is_size_info_continues:\n",
    "                                last_assign_tok_idx = idx_idx\n",
    "                            is_size_info_continues = False\n",
    "                        if idx > last_size_info_idx and any(rel.startswith(\"ont:obj:\") for rel in idx_rels):\n",
    "                            for size_idx in range(last_size_info_start_idx, last_size_info_idx + 1):\n",
    "                                macro_rels.append({\"rel\": \"size\", \"from\": size_idx, \"to\": idx})\n",
    "                else:\n",
    "                    for idx_idx, idx in enumerate(sent_idx_list):\n",
    "                        idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "                        if any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                            is_size_info_continues = False\n",
    "                            for size_idx in sent_idx_list[last_assign_tok_idx:idx_idx]:\n",
    "                                size_idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == size_idx]\n",
    "                                if \"ont:size\" in size_idx_rels:\n",
    "                                    macro_rels.append({\"rel\": \"size\", \"from\": size_idx, \"to\": idx})\n",
    "                        else:\n",
    "                            if \"ont:size\" in idx_rels:\n",
    "                                if not is_size_info_continues:\n",
    "                                    last_assign_tok_idx = idx_idx\n",
    "                                is_size_info_continues = True\n",
    "                        # even if sentence is ended by size info, it is dropped, because all objects were defined by previous size infos\n",
    "\n",
    "        # different sentences\n",
    "        dangling_prop_idx_list = []\n",
    "        no_size_sent_list = []\n",
    "        size_sent_list = []\n",
    "        for idx in range(len(toks)):\n",
    "            idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "            if any(rel.startswith(\"ont:attr:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                if not any(mrel[\"from\"] == idx for mrel in macro_rels if mrel[\"rel\"] == \"prop\"):\n",
    "                    dangling_prop_idx_list.append(idx)\n",
    "            if any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                if not any(mrel[\"to\"] == idx for mrel in macro_rels if mrel[\"rel\"] == \"size\"):\n",
    "                    for sent_idx, sent_range in enumerate(sentence_ranges):\n",
    "                        if idx >= sent_range[0] and idx < sent_range[1]:\n",
    "                            no_size_sent_list.append(sent_idx)\n",
    "                            break\n",
    "            if \"ont:size\" in idx_rels:\n",
    "                for sent_idx, sent_range in enumerate(sentence_ranges):\n",
    "                    if idx >= sent_range[0] and idx < sent_range[1]:\n",
    "                        size_sent_list.append(sent_idx)\n",
    "                        break\n",
    "        for prop_idx in dangling_prop_idx_list:\n",
    "            obj_found = False\n",
    "            for tok_idx in range(prop_idx - 1, -1, -1):\n",
    "                idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                if any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                    macro_rels.append({\"rel\": \"prop\", \"from\": prop_idx, \"to\": tok_idx})\n",
    "                    obj_found = True\n",
    "                    break\n",
    "            if not obj_found:\n",
    "                for tok_idx in range(prop_idx + 1, len(toks)):\n",
    "                    idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == tok_idx]\n",
    "                    if any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                        macro_rels.append({\"rel\": \"prop\", \"from\": prop_idx, \"to\": tok_idx})\n",
    "                        break\n",
    "        if len(size_sent_list) > 0 and len(no_size_sent_list) > 0:\n",
    "            for no_size_sent_idx in no_size_sent_list:\n",
    "                closest_size_sent_idx = min(\n",
    "                    [(abs(size_sent_idx - no_size_sent_idx), size_sent_idx) for size_sent_idx in size_sent_list], key=lambda x: x[0]\n",
    "                )[1]\n",
    "                size_idx_list = [\n",
    "                    idx for idx in list(range(sentence_ranges[closest_size_sent_idx][0], sentence_ranges[closest_size_sent_idx][1]))\n",
    "                    if \"ont:size\" in [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "                ]\n",
    "                for idx in list(range(sentence_ranges[no_size_sent_idx][0], sentence_ranges[no_size_sent_idx][1])):\n",
    "                    idx_rels = [rel[\"rel\"] for rel in rel_list if rel[\"to\"] == idx]\n",
    "                    if any(rel.startswith(\"ont:obj:\") for rel in idx_rels):  # any() returns False on empty input\n",
    "                        # according to the processing above, all objects in sentence are not connected to size info, so no check is needed\n",
    "                        for size_idx in size_idx_list:\n",
    "                            macro_rels.append({\"rel\": \"size\", \"from\": size_idx, \"to\": idx})\n",
    "\n",
    "        return macro_rels\n",
    "\n",
    "    def _normalize_attr(ont, morph_an, attr_name):\n",
    "        norm_attr_name = morph_an.parse(attr_name)[0].normal_form\n",
    "        res = ont.query(\n",
    "            \"SELECT DISTINCT ?attr_obj ?class_obj \"\n",
    "            \"WHERE { \"\n",
    "            \"    VALUES ?class_obj {local:gender local:season local:material} \"\n",
    "            \"    ?attr_obj local:is_included ?class_obj . \"\n",
    "            \"    ?attr_obj local:is_included local:parsed_attributes . \"\n",
    "            f\"    ?attr_obj local:has_name \\\"{norm_attr_name}\\\" . \"\n",
    "            \"}\"\n",
    "        )\n",
    "        assert len(res) == 1\n",
    "        res = list(res)\n",
    "        attr_obj = res[0][0].n3(ont.namespace_manager)\n",
    "        attr_type = res[0][1].n3(ont.namespace_manager)\n",
    "        if attr_type == \"local:gender\":\n",
    "            key = \"gender\"\n",
    "            if attr_obj == \"local:Man\":\n",
    "                val = ClothFact.Gender.MAN\n",
    "            elif attr_obj == \"local:Woman\":\n",
    "                val = ClothFact.Gender.WOMAN\n",
    "            elif attr_obj == \"local:Unisex\":\n",
    "                val = ClothFact.Gender.UNISEX\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown gender object: {attr_obj}\")\n",
    "        elif attr_type == \"local:season\":\n",
    "            key = \"season\"\n",
    "            if attr_obj == \"local:DemiSeason\":\n",
    "                val = ClothFact.Season.DEMI_SEASON\n",
    "            elif attr_obj == \"local:Winter\":\n",
    "                val = ClothFact.Season.WINTER\n",
    "            elif attr_obj == \"local:Summer\":\n",
    "                val = ClothFact.Season.SUMMER\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown season object: {attr_obj}\")\n",
    "        elif attr_type == \"local:material\":\n",
    "            key = \"material\"\n",
    "            val = attr_obj\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown attribute type: {attr_type}\")\n",
    "        return key, val\n",
    "\n",
    "    relation_list, toks, sentence_ranges = _get_all_word_relations(text, ont, ont_stat, morph_an, size_rule)\n",
    "    macro_rel_list = _infer_macro_relations(relation_list, sentence_ranges)\n",
    "\n",
    "    out_obj_list = []\n",
    "    for idx in range(len(toks)):\n",
    "        rels = [rel[\"rel\"] for rel in relation_list if rel[\"to\"] == idx]\n",
    "        obj_rel_list = [rel for rel in rels if rel.startswith(\"ont:obj:\")]\n",
    "        assert len(obj_rel_list) <= 1\n",
    "        if len(obj_rel_list) == 1:\n",
    "            prop_dict = {}\n",
    "            for m_rel in macro_rel_list:\n",
    "                if m_rel[\"rel\"] == \"prop\" and m_rel[\"to\"] == idx:\n",
    "                    k, v = _normalize_attr(ont, morph_an, toks[m_rel[\"from\"]])\n",
    "                    prop_dict[k] = v\n",
    "\n",
    "            size_text = \"\"\n",
    "            for m_rel in macro_rel_list:\n",
    "                if m_rel[\"rel\"] == \"size\" and m_rel[\"to\"] == idx:\n",
    "                    tok = toks[m_rel[\"from\"]]\n",
    "                    size_text += f\" {tok}\" if len(size_text) > 0 and not tok.startswith(\"-\") else tok\n",
    "            if len(size_text) > 0:\n",
    "                parser = YrgParser(size_rule)\n",
    "                matched_trees = list(parser.findall(size_text))\n",
    "                assert len(matched_trees) > 0\n",
    "                # we take only the longest match, from left to right\n",
    "                matched_trees = sorted(matched_trees, key=lambda m: (m.span.stop - m.span.start, m.span.start), reverse=True)\n",
    "                size_info = matched_trees[0].fact\n",
    "            else:\n",
    "                size_info = None\n",
    "            out_obj_list.append(\n",
    "                ClothFact(obj_rel_list[0], toks[idx], size_info, prop_dict)\n",
    "            )\n",
    "\n",
    "    return out_obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3b7391-86bd-4d0d-a0bf-686a39d26c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbab5dee720>,\n",
       " <__main__.ClothFact at 0x7cbae8240e90>,\n",
       " <__main__.ClothFact at 0x7cbab5df80e0>,\n",
       " <__main__.ClothFact at 0x7cbab6f12c60>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_facts(\n",
    "    \"Отдам вещи на девочку р 80-92, Большая юбка, демисезонные большие джинсы и красные кофты бязь\",\n",
    "    ontology_g, ont_stat, MORPH_AN, r_size_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc197705-6ad0-49a6-8b86-b5f2d34ac60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbab6df9640>,\n",
       " <__main__.ClothFact at 0x7cbab758c5f0>,\n",
       " <__main__.ClothFact at 0x7cbab6ac8950>,\n",
       " <__main__.ClothFact at 0x7cbab6acb470>,\n",
       " <__main__.ClothFact at 0x7cbab6acabd0>,\n",
       " <__main__.ClothFact at 0x7cbab6acb9e0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_facts(\n",
    "    \"Куртка с капюшоном lskdjf. Мужской плащ, Джинсы мужские и женские. Куртка с джинсами.\", ontology_g, ont_stat, MORPH_AN, r_size_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc906ee-2cc4-40e1-8111-1c0d26cb631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbaad3a3410>,\n",
       " <__main__.ClothFact at 0x7cbaae5b8b60>,\n",
       " <__main__.ClothFact at 0x7cbaadc5b740>,\n",
       " <__main__.ClothFact at 0x7cbab01f48f0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_facts(\n",
    "    \"Отдам вещи на девочку р 80-92. Большая юбка, зелёные осенние джинсы и красные кофты\", ontology_g, ont_stat, MORPH_AN, r_size_info\n",
    ")\n",
    "extract_facts(\n",
    "    \"Отдам вещи на девочку р 80-92, большая юбка, зелёные осенние джинсы и красные кофты\", ontology_g, ont_stat, MORPH_AN, r_size_info\n",
    ")\n",
    "extract_facts(\n",
    "    \"Отдам вещи на девочку р 80-92: большая юбка, зелёные осенние джинсы и красные кофты\", ontology_g, ont_stat, MORPH_AN, r_size_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28727212-7adb-4ff6-b021-1b7aeaa74c3f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2165f3-3f5e-406f-90da-ecbc1e852cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert \"ё\" to \"е\", correct typos, correct terms, correct (unify) dashes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad495b-ad4e-4a7e-881f-c6c6047e0e9e",
   "metadata": {},
   "source": [
    "Words are conversted to normal form by parsers, so text preprocessing is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd68dc9-718f-498f-8263-1630a72cd078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbab08910d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_facts(\"8. Кожаная куртка р. 40\", ontology_g, ont_stat, MORPH_AN, r_size_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2215c375-7b44-4472-b493-5b7249ff2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = YrgParser(r_size_info)\n",
    "# match = next(parser.findall(\" 46-48 размера\"))\n",
    "# match.fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "705567dc-e034-4907-876c-b0479fb53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ad_facts = [extract_facts(text, ontology_g, ont_stat, MORPH_AN, r_size_info) for text in ads_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed4aa64-72c6-498a-bacb-5543e799d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_req_facts = [extract_facts(text, ontology_g, ont_stat, MORPH_AN, r_size_info) for text in requests_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "737805a6-17d7-4df6-8348-7dd715af3bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ont:obj:local:obj108357N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj109168N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj108154N: 2 advertisements, 0 requests\n",
      "ont:obj:local:obj117279N: 3 advertisements, 0 requests\n",
      "ont:obj:local:obj149005N: 2 advertisements, 0 requests\n",
      "ont:obj:local:obj108476N: 3 advertisements, 0 requests\n",
      "ont:obj:local:obj124847N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj148759N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj147466N: 2 advertisements, 0 requests\n",
      "ont:obj:local:obj6892N: 3 advertisements, 30 requests\n",
      "ont:obj:local:obj124399N: 1 advertisements, 2 requests\n",
      "ont:obj:local:obj109428N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj1256N: 14 advertisements, 6 requests\n",
      "ont:obj:local:obj124080N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj109582N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj123944N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj126078N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj140889N: 1 advertisements, 1 requests\n",
      "ont:obj:local:obj108393N: 4 advertisements, 1 requests\n",
      "ont:obj:local:obj108533N: 3 advertisements, 1 requests\n",
      "ont:obj:local:obj108468N: 3 advertisements, 0 requests\n",
      "ont:obj:local:obj108159N: 1 advertisements, 2 requests\n",
      "ont:obj:local:obj141427N: 3 advertisements, 0 requests\n",
      "ont:obj:local:obj108171N: 1 advertisements, 1 requests\n",
      "ont:obj:local:obj108139N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj108104N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj112368N: 2 advertisements, 0 requests\n",
      "ont:obj:local:obj108065N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj112224N: 4 advertisements, 1 requests\n",
      "ont:obj:local:obj147510N: 4 advertisements, 0 requests\n",
      "ont:obj:local:obj108381N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj108048N: 2 advertisements, 23 requests\n",
      "ont:obj:local:obj108194N: 2 advertisements, 0 requests\n",
      "ont:obj:local:obj108170N: 1 advertisements, 1 requests\n",
      "ont:obj:local:obj112527N: 2 advertisements, 1 requests\n",
      "ont:obj:local:obj109624N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj152472N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj126987N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj131463N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj118086N: 3 advertisements, 0 requests\n",
      "ont:obj:local:obj108584N: 1 advertisements, 6 requests\n",
      "ont:obj:local:obj118277N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj108882N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj3135N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj107762N: 1 advertisements, 0 requests\n",
      "ont:obj:local:obj108616N: 0 advertisements, 1 requests\n",
      "ont:obj:local:obj109166N: 0 advertisements, 3 requests\n",
      "ont:obj:local:obj107813N: 0 advertisements, 1 requests\n",
      "ont:obj:local:obj8114N: 0 advertisements, 6 requests\n",
      "ont:obj:local:obj108643N: 0 advertisements, 5 requests\n",
      "ont:obj:local:obj146680N: 0 advertisements, 1 requests\n",
      "ont:obj:local:obj108676N: 0 advertisements, 1 requests\n",
      "ont:obj:local:obj5185N: 0 advertisements, 1 requests\n",
      "ont:obj:local:obj140884N: 0 advertisements, 2 requests\n",
      "ont:obj:local:obj108613N: 0 advertisements, 1 requests\n"
     ]
    }
   ],
   "source": [
    "fact_counts = {}\n",
    "for ad_facts in all_ad_facts:\n",
    "    for ad_fact in ad_facts:\n",
    "        f_name = ad_fact.class_name\n",
    "        if f_name not in fact_counts:\n",
    "            fact_counts[f_name] = [0, 0]\n",
    "        fact_counts[f_name][0] += 1\n",
    "for req_facts in all_req_facts:\n",
    "    for req_fact in req_facts:\n",
    "        f_name = req_fact.class_name\n",
    "        if f_name not in fact_counts:\n",
    "            fact_counts[f_name] = [0, 0]\n",
    "        fact_counts[f_name][1] += 1\n",
    "\n",
    "for fact_name, (ad_cnt, req_cnt) in fact_counts.items():\n",
    "    print(f\"{fact_name}: {ad_cnt} advertisements, {req_cnt} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0e7106-9d52-4007-b6e1-8688b4412bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.5 ms, sys: 15.9 ms, total: 75.4 ms\n",
      "Wall time: 75 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbaa62a8e60>,\n",
       " <__main__.ClothFact at 0x7cbaa2085c70>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "extract_facts(\"джинсовые куртка с кофтой\", ontology_g, ont_stat, MORPH_AN, r_size_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b9b4d19-b594-42c4-9b1c-57641578b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 ms, sys: 12.6 ms, total: 49.4 ms\n",
      "Wall time: 48.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.ClothFact at 0x7cbaae58d760>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "extract_facts(\"куртка из кожи\", ontology_g, ont_stat, MORPH_AN, r_size_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcec9e2-fa95-49e3-94c1-ac70bf0fb979",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0701cd74-2739-454c-b72a-b2c42281ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_facts_close(ont, req_facts, ad_facts):\n",
    "    for req_fact in req_facts:\n",
    "        for ad_fact in ad_facts:\n",
    "            if req_fact.class_name != ad_fact.class_name:\n",
    "                if _get_relation(ont, req_fact.parsed_name, ad_fact.parsed_name, is_attr=False) != 1:\n",
    "                    continue\n",
    "            ad_size = ad_fact.parsed_size_info\n",
    "            req_size = req_fact.parsed_size_info\n",
    "            if req_size is not None and ad_size is not None:\n",
    "                if max(req_size) < min(ad_size) or min(req_size) > max(ad_size):\n",
    "                    # any intersection of sized is a match, but no intersection means no match\n",
    "                    continue\n",
    "            is_match = True\n",
    "            for attr_name in req_fact.props.keys():\n",
    "                ad_attr = ad_fact.props.get(attr_name, None)\n",
    "                req_attr = req_fact.props.get(attr_name, None)\n",
    "                if req_attr is not None and ad_attr is not None:\n",
    "                    # different attributes are not match, but if this attribute is omitted in request or ad, this is still match\n",
    "                    if req_attr != ad_attr:\n",
    "                        is_match = False\n",
    "                        break\n",
    "            if not is_match:\n",
    "                continue\n",
    "            # even one matched fact is complete match between request and ad\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def predict_by_facts(ont, req_fact_list, ad_fact_list):\n",
    "    predictions = {}\n",
    "    for req_id, req_facts in enumerate(req_fact_list, start=1):\n",
    "        found_list = []\n",
    "        for ad_id, ad_facts in enumerate(ad_fact_list, start=1):\n",
    "            if are_facts_close(ont, req_facts, ad_facts):\n",
    "                found_list.append(str(ad_id))\n",
    "        if len(found_list) > 0:\n",
    "            predictions[str(req_id)] = found_list.copy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665f8125-9152-4406-9c25-884c7b619632",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_markup = predict_by_facts(ontology_g, all_req_facts, all_ad_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70d88008-02ea-4689-98c6-b2167c8450bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 122, 'FP': 83, 'TN': 87129, 'FN': 488}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = metrics.calc_confusion_matrix(true_markup, pred_markup, n_ads=len(ads_raw), n_requests=len(requests_raw))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f9a6a7-79ca-4e5c-bf5d-9c472ebd9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"False positives:\")\n",
    "# for req_id, matched_ad_ids in pred_markup.items():\n",
    "#     found_fp_ids = []\n",
    "#     for ad_id in matched_ad_ids:\n",
    "#         if req_id not in true_markup or ad_id not in true_markup[req_id]:\n",
    "#             found_fp_ids.append(ad_id)\n",
    "#     if len(found_fp_ids) > 0:\n",
    "#         print(f\"\\t{req_id}. \\\"{requests_raw[int(req_id) - 1].strip()}\\\" => {all_req_facts[int(req_id) - 1]}\")\n",
    "#     for ad_id in found_fp_ids:\n",
    "#         print(f\"\\t\\t{ad_id}) {ads_raw[int(ad_id) - 1].strip()} => {all_ad_facts[int(ad_id) - 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3aaa536-a1ee-41dd-8fa8-7d30d1f44af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9934982122930472,\n",
       " 'precision': 0.5951219512195122,\n",
       " 'recall': 0.2,\n",
       " 'f1': 0.29938650306748466}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = metrics.calc_all_stats(confusion_matrix)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83872ea7-2336-44db-a648-ab10741196fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\tMetric\t\t|\tOld Value\t|\tNew Value\t|\tDiff\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tTP\t\t|\t242\t\t|\t122\t\t|\t📉 -120\t|\n",
      "|\tFP\t\t|\t392\t\t|\t83\t\t|\t📉 -309\t|\n",
      "|\tTN\t\t|\t86823\t\t|\t87129\t\t|\t📈 306\t|\n",
      "|\tFN\t\t|\t365\t\t|\t488\t\t|\t📈 123\t|\n",
      "|\tPrec\t\t|\t0.382\t\t|\t0.595\t\t|\t📈 0.213\t|\n",
      "|\tRecall\t\t|\t0.399\t\t|\t0.200\t\t|\t📉 -0.199\t|\n",
      "|\tF1\t\t|\t0.390\t\t|\t0.299\t\t|\t📉 -0.091\t|\n",
      "\n",
      "F1 📉 decreased by 0.091, down to 29.9%, which is a significant fall.\n"
     ]
    }
   ],
   "source": [
    "metrics.compare_with_saved_stats(stats, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a86a0c-8e79-4235-a4de-817e8fdf9eb4",
   "metadata": {},
   "source": [
    "## Topics for Learning Yargy\n",
    "\n",
    "Documentation:\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/index.ipynb\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/ref.ipynb\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/cookbook.ipynb\n",
    "\n",
    "Topics for paying attention to:\n",
    "1. Main terms and entities: rule, fact (+interpretation stage), predicate, gazetteer\n",
    "1. Multiple values for single attribute are not supported\n",
    "1. Rules for arbitrary order of words (\"adjacency\") are not supported, so they are generated\n",
    "1. Hierarchical relationship of objects in rules looks not supported (i.e. input to rules are bare words, not objects), but it needs to be checked\n",
    "1. We can match word not only literally or by normal form, but also by POS, regex, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903ddd3-5500-4074-b71d-63cc475897ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
