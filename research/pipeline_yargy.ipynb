{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f30ca-0c7a-4e9a-a5b8-ff293ef4851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(NOTEBOOK_DIR, '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e368ffd0-578b-474a-aeae-d75e83834bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "\n",
    "import IPython\n",
    "from yargy.interpretation import fact as yrg_fact, attribute as yrg_attr\n",
    "from yargy.pipelines import morph_pipeline as yrg_morph_pipeline\n",
    "from yargy import rule as yrg_rule, or_ as yrg_r_or\n",
    "from yargy.predicates import eq as yrg_rp_eq\n",
    "from yargy import Parser as YrgParser\n",
    "from ipymarkup import show_span_ascii_markup as natasha_show_markup\n",
    "\n",
    "from utils import dataset_utils\n",
    "from utils import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663c530-9dcf-4126-bbbb-b85faa2943db",
   "metadata": {},
   "source": [
    "# Search by word ontologies with YARGY parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd883-a975-4be6-bae8-6dbf2a182135",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cf9941-1940-4e1c-bc84-0333f1f4677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUESTS_FILE = \"../data/request_db.txt\"\n",
    "ADS_FILE = \"../data/ads_db.txt\"\n",
    "MATCHING_FILE = \"../data/matching_db.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f51ca95-b069-496f-8806-8716bc2e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ADS_FILE, encoding=\"utf-8\") as f:\n",
    "    ads_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56949b0-0bb4-40f3-a4df-37cee9ff1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(REQUESTS_FILE, encoding=\"utf-8\") as f:\n",
    "    requests_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357b3da0-cecd-4312-8bb8-d78563d1e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_markup = dataset_utils.load_matching_data(MATCHING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397f814-7690-447a-819a-d64a49dc317e",
   "metadata": {},
   "source": [
    "## Constructing Ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987674c-3b4e-4a8a-94a8-4f0785448288",
   "metadata": {},
   "source": [
    "### Service Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b54d07-8e27-4765-a4f6-8e23f5a9ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rule_obj_w_attrs(o_obj, n_obj, adj_dict):\n",
    "    # attributing all adjectives to the object\n",
    "    attributed_dict = {\n",
    "        # we have to copy each adjectives, because they are modified when parser is created (MorphPipelineScheme to MorphPipeline),\n",
    "        # but user can potentially pass same adjective instances for multiple objects\n",
    "        prop_name: [copy.deepcopy(adj.interpretation(getattr(o_obj, prop_name).const(adj.pipeline.lines[0]))) for adj in adj_list]\n",
    "        for prop_name, adj_list in adj_dict.items()\n",
    "    }\n",
    "\n",
    "    # generate rules for all positions of attr adjectives and object noun\n",
    "    rule_variants = []\n",
    "    for perm_item_list in itertools.permutations(list(attributed_dict.keys()) + [n_obj]):\n",
    "        rule_variants.append(\n",
    "            yrg_rule(\n",
    "                *(\n",
    "                    yrg_r_or(*attributed_dict[p_item]).optional() if p_item is not n_obj else p_item\n",
    "                    for p_item in perm_item_list\n",
    "                )\n",
    "            ).interpretation(o_obj)\n",
    "        )\n",
    "    o_attr_variants = yrg_fact(f\"{o_obj.__name__}_attr_vars\", [\"value\"])\n",
    "    high_level_or_rule = yrg_r_or(*rule_variants).interpretation(o_attr_variants.value)\n",
    "\n",
    "    return high_level_or_rule\n",
    "\n",
    "\n",
    "def add_object_parser(obj_class_name, obj_noun_list, obj_prop_dict, parser_list):\n",
    "    o_obj = yrg_fact(obj_class_name, list(obj_prop_dict.keys()))\n",
    "    n_obj = yrg_morph_pipeline(obj_noun_list)\n",
    "    r_obj = create_rule_obj_w_attrs(\n",
    "        o_obj,\n",
    "        n_obj,\n",
    "        obj_prop_dict,\n",
    "    )\n",
    "    parser_list.append(YrgParser(r_obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16d00f-a595-43d0-a976-54bdd6e6ad1a",
   "metadata": {},
   "source": [
    "### Clothes Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2049f09-ee2a-4984-b15f-c7b454618789",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_parsers = []\n",
    "# all_clothes_list = []\n",
    "\n",
    "# === general attributes ===\n",
    "\n",
    "gen_attributes = {}\n",
    "\n",
    "gen_attributes[\"gender\"] = [\n",
    "    yrg_morph_pipeline([\n",
    "        \"–º—É–∂—Å–∫–æ–π\",\n",
    "        \"–º—É–∂\",\n",
    "        \"–º—É–∂.\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"–∂–µ–Ω—Å–∫–∏–π\",\n",
    "        \"–∂–µ–Ω\",\n",
    "        \"–∂–µ–Ω.\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"—É–Ω–∏—Å–µ–∫—Å\",\n",
    "        \"—é–Ω–∏—Å–µ–∫—Å\",\n",
    "    ]),\n",
    "]\n",
    "\n",
    "gen_attributes[\"season\"] = [\n",
    "    yrg_morph_pipeline([\n",
    "        \"–¥–µ–º—Å–µ–∑–æ–Ω\",\n",
    "        \"–¥–µ–º–∏—Å–µ–∑–æ–Ω\",\n",
    "        \"–¥–µ–º–∏—Å–µ–∑–æ–Ω–Ω—ã–π\",\n",
    "        \"–≤–µ—Å–µ–Ω–Ω–∏–π\",\n",
    "        \"–≤–µ—Å–Ω–∞\",\n",
    "        \"–æ—Å–µ–Ω–Ω–∏–π\",\n",
    "        \"–æ—Å–µ–Ω—å\",\n",
    "        \"–≤–µ—Å–Ω–∞-–æ—Å–µ–Ω—å\",\n",
    "        \"–æ—Å–µ–Ω—å-–≤–µ—Å–Ω–∞\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"–∑–∏–º–Ω–∏–π\",\n",
    "        \"–∑–∏–º–∞\",\n",
    "        \"–∑–∏–º\",\n",
    "        \"–∑–∏–º–Ω\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"–ª–µ—Ç–Ω–∏–π\",\n",
    "        \"–ª–µ—Ç–æ\",\n",
    "        \"–ª–µ—Ç\",\n",
    "        \"–ª–µ—Ç–Ω\",\n",
    "    ]),\n",
    "]\n",
    "\n",
    "gen_attributes[\"material\"] = [\n",
    "    yrg_morph_pipeline([\n",
    "        \"–¥–∂–∏–Ω—Å–æ–≤—ã–π\",\n",
    "        \"–¥–∂–∏–Ω—Å–∞\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"–∫–æ–∂–∞–Ω—ã–π\",\n",
    "        \"–∫–æ–∂–∞\",\n",
    "    ]),\n",
    "    yrg_morph_pipeline([\n",
    "        \"—Å–∏–Ω—Ç–µ–ø–æ–Ω–æ–≤—ã–π\",\n",
    "        \"—Å–∏–Ω—Ç–µ–ø–æ–Ω\",\n",
    "    ]),\n",
    "]\n",
    "\n",
    "# o_size_info = yrg_fact(\"SizeInfoStr\", [\"content\"])\n",
    "# n_size_word = yrg_morph_pipeline([\n",
    "#     \"—Ä–∞–∑–º–µ—Ä\",\n",
    "#     \"—Ä\",\n",
    "#     \"p.\",\n",
    "# ]),\n",
    "# r_size_info = yrg_r_or(\n",
    "#     yrg_rule(\n",
    "#         n_clothes_words,\n",
    "#         n_size_word.optional(),\n",
    "#         o_size_info,\n",
    "#     )\n",
    "# ).interpretation(o_size_info.content)\n",
    "# # https://tri-land.ru/info/sizes/detskaya-odezhda/\n",
    "# o_size_range = yrg_fact(\"SizeRange\", [\"from\", \"to\"])\n",
    "\n",
    "# === objects ===\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Coat\",\n",
    "    obj_noun_list=[\n",
    "        \"–ø–∞–ª—å—Ç–æ\",\n",
    "        \"–ø–æ–ª—É–ø–∞–ª—å—Ç–æ\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **gen_attributes,\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Jacket\",\n",
    "    obj_noun_list=[\n",
    "        \"–∫—É—Ä—Ç–∫–∞\",\n",
    "        \"–≤–µ—Ç—Ä–æ–≤–∫–∞\",\n",
    "        \"–±–æ–º–±–µ—Ä\",\n",
    "        \"–∫—É—Ä—Ç–∫–∞-–±–æ–º–±–µ—Ä\",\n",
    "        \"–ª–µ—Ç–Ω–∞—è –∫—É—Ä—Ç–∫–∞\",\n",
    "        \"–∫—É—Ä—Ç–∫–∞ –ª–µ—Ç–Ω–∞—è\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **gen_attributes,\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Sweater\",\n",
    "    obj_noun_list=[\n",
    "        \"–∫–æ—Ñ—Ç–∞\",\n",
    "        \"—Å—Ñ–∏—Ç–µ—Ä\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **gen_attributes,\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Blouse\",\n",
    "    obj_noun_list=[\n",
    "        \"–±–ª—É–∑–∫–∞\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **{k: v for k, v in gen_attributes.items() if k != \"gender\"},  # it is supposed that blouses are only for women\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Trousers\",\n",
    "    obj_noun_list=[\n",
    "        \"—à—Ç–∞–Ω—ã\",\n",
    "        \"–¥–∂–∏–Ω—Å—ã\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **gen_attributes,\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Skirt\",\n",
    "    obj_noun_list=[\n",
    "        \"—é–±–∫–∞\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **{k: v for k, v in gen_attributes.items() if k != \"gender\"},  # it is supposed that skirts are only for women\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")\n",
    "\n",
    "add_object_parser(\n",
    "    obj_class_name=\"Shirt\",\n",
    "    obj_noun_list=[\n",
    "        \"—Ä—É–±–∞—à–∫–∞\",\n",
    "    ],\n",
    "    obj_prop_dict={\n",
    "        **gen_attributes,\n",
    "    },\n",
    "    parser_list=rule_parsers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6c62e3-409e-49a1-81a2-3b51da82a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules for 7 objects were created\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rules for {len(rule_parsers)} objects were created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28727212-7adb-4ff6-b021-1b7aeaa74c3f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e08c9a7-8b26-43a6-877c-4f78ea02bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facts(text, rule_parsers):\n",
    "    trees = []\n",
    "    for parser in rule_parsers:\n",
    "        matched_trees = list(parser.findall(text))\n",
    "        if len(matched_trees) == 0:\n",
    "            continue\n",
    "        # for each parser we take only longest matches, that aren't overlapped from left to right\n",
    "        matched_trees = sorted(matched_trees, key=lambda m: (m.span.stop - m.span.start, m.span.start), reverse=True)\n",
    "        taken_trees = [matched_trees[0]]\n",
    "        for m_tree in matched_trees[1:]:\n",
    "            if all(m_tree.span.stop <= taken_tree.span.start or m_tree.span.start >= taken_tree.span.stop for taken_tree in taken_trees):\n",
    "                taken_trees.append(m_tree)\n",
    "        trees += taken_trees\n",
    "    return [tree.fact for tree in trees]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad495b-ad4e-4a7e-881f-c6c6047e0e9e",
   "metadata": {},
   "source": [
    "Words are conversted to normal form by parsers, so text preprocessing is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705567dc-e034-4907-876c-b0479fb53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ad_facts = [get_facts(text, rule_parsers) for text in ads_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed4aa64-72c6-498a-bacb-5543e799d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_req_facts = [get_facts(text, rule_parsers) for text in requests_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737805a6-17d7-4df6-8348-7dd715af3bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat: 4 advertisements, 33 requests\n",
      "Sweater: 3 advertisements, 0 requests\n",
      "Trousers: 5 advertisements, 1 requests\n",
      "Blouse: 1 advertisements, 0 requests\n",
      "Shirt: 2 advertisements, 1 requests\n",
      "Jacket: 3 advertisements, 24 requests\n",
      "Skirt: 4 advertisements, 0 requests\n"
     ]
    }
   ],
   "source": [
    "fact_counts = {}\n",
    "for ad_facts in all_ad_facts:\n",
    "    for ad_fact in ad_facts:\n",
    "        f_name = ad_fact.__class__.__name__\n",
    "        if f_name not in fact_counts:\n",
    "            fact_counts[f_name] = [0, 0]\n",
    "        fact_counts[f_name][0] += 1\n",
    "for req_facts in all_req_facts:\n",
    "    for req_fact in req_facts:\n",
    "        f_name = req_fact.__class__.__name__\n",
    "        if f_name not in fact_counts:\n",
    "            fact_counts[f_name] = [0, 0]\n",
    "        fact_counts[f_name][1] += 1\n",
    "\n",
    "for fact_name, (ad_cnt, req_cnt) in fact_counts.items():\n",
    "    print(f\"{fact_name}: {ad_cnt} advertisements, {req_cnt} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0e7106-9d52-4007-b6e1-8688b4412bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 ms, sys: 2 ms, total: 188 ms\n",
      "Wall time: 187 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Jacket(\n",
       "     gender=None,\n",
       "     season=None,\n",
       "     material='–¥–∂–∏–Ω—Å–æ–≤—ã–π'\n",
       " ),\n",
       " Sweater(\n",
       "     gender=None,\n",
       "     season=None,\n",
       "     material=None\n",
       " )]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_facts(\"–¥–∂–∏–Ω—Å–æ–≤—ã–µ –∫—É—Ä—Ç–∫–∞ —Å –∫–æ—Ñ—Ç–æ–π\", rule_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9b4d19-b594-42c4-9b1c-57641578b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 ms, sys: 999 Œºs, total: 22.7 ms\n",
      "Wall time: 22.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Jacket(\n",
       "     gender=None,\n",
       "     season=None,\n",
       "     material=None\n",
       " )]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_facts(\"–∫—É—Ä—Ç–∫–∞ –∏–∑ –∫–æ–∂–∏\", rule_parsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcec9e2-fa95-49e3-94c1-ac70bf0fb979",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0701cd74-2739-454c-b72a-b2c42281ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_facts_close(req_facts, ad_facts):\n",
    "    for req_fact in req_facts:\n",
    "        for ad_fact in ad_facts:\n",
    "            if req_fact.__class__.__name__ != ad_fact.__class__.__name__:\n",
    "                continue\n",
    "            is_match = True\n",
    "            for attr_name in req_fact.__attributes__:\n",
    "                ad_attr = getattr(ad_fact, attr_name)\n",
    "                req_attr = getattr(req_fact, attr_name)\n",
    "                if req_attr is not None and req_attr != ad_attr:\n",
    "                    # different attributes are not match, but if this attribute is omitted in request, this is still match\n",
    "                    is_match = False\n",
    "                    break\n",
    "            if not is_match:\n",
    "                continue\n",
    "            # even one matched fact is complete match between request and ad\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def predict_by_facts(req_fact_list, ad_fact_list):\n",
    "    predictions = {}\n",
    "    for req_id, req_facts in enumerate(req_fact_list, start=1):\n",
    "        found_list = []\n",
    "        for ad_id, ad_facts in enumerate(ad_fact_list, start=1):\n",
    "            if are_facts_close(req_facts, ad_facts):\n",
    "                found_list.append(str(ad_id))\n",
    "        if len(found_list) > 0:\n",
    "            predictions[str(req_id)] = found_list.copy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "665f8125-9152-4406-9c25-884c7b619632",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_markup = predict_by_facts(all_req_facts, all_ad_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d88008-02ea-4689-98c6-b2167c8450bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 94, 'FP': 82, 'TN': 87143, 'FN': 503}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = metrics.calc_confusion_matrix(true_markup, pred_markup, n_ads=len(ads_raw), n_requests=len(requests_raw))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3aaa536-a1ee-41dd-8fa8-7d30d1f44af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9933387989342078,\n",
       " 'precision': 0.5340909090909091,\n",
       " 'recall': 0.1574539363484087,\n",
       " 'f1': 0.24320827943078913}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = metrics.calc_all_stats(confusion_matrix)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83872ea7-2336-44db-a648-ab10741196fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\tMetric\t\t|\tOld Value\t|\tNew Value\t|\tDiff\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tTP\t\t|\t216\t\t|\t94\t\t|\tüìâ -122\t|\n",
      "|\tFP\t\t|\t418\t\t|\t82\t\t|\tüìâ -336\t|\n",
      "|\tTN\t\t|\t86810\t\t|\t87143\t\t|\tüìà 333\t|\n",
      "|\tFN\t\t|\t378\t\t|\t503\t\t|\tüìà 125\t|\n",
      "|\tPrec\t\t|\t0.341\t\t|\t0.534\t\t|\tüìà 0.193\t|\n",
      "|\tRecall\t\t|\t0.364\t\t|\t0.157\t\t|\tüìâ -0.206\t|\n",
      "|\tF1\t\t|\t0.352\t\t|\t0.243\t\t|\tüìâ -0.109\t|\n",
      "\n",
      "F1 üìâ decreased by 0.109, down to 24.3%, which is a significant fall.\n"
     ]
    }
   ],
   "source": [
    "metrics.compare_with_saved_stats(stats, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a86a0c-8e79-4235-a4de-817e8fdf9eb4",
   "metadata": {},
   "source": [
    "## Topics for Learning YARGY\n",
    "\n",
    "Documentation:\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/index.ipynb\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/ref.ipynb\n",
    "* https://nbviewer.org/github/natasha/yargy/blob/master/docs/cookbook.ipynb\n",
    "\n",
    "Topics for paying attention to:\n",
    "1. Multiple values for single attribute are not supported\n",
    "2. Rules for arbitrary order of words (\"adjacency\") are not supported, so they are generated\n",
    "3. Hierarchical relationship of objects in rules looks not supported (i.e. input to rules are bare words, not objects), but it needs to be checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903ddd3-5500-4074-b71d-63cc475897ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
