{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881a427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b164cd-d98b-48d2-9089-4b3fc1bdf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_SETTINGS = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ce300-80ff-4a83-80bf-3a94df754cb4",
   "metadata": {},
   "source": [
    "# Calculate Metrics for CLIP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745569d1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da0f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_markup(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "            sep_ind = line.find(\"\\\"\")\n",
    "            path = (\"../\" + line[:sep_ind]).strip()\n",
    "            desc = line[sep_ind + 1:].strip()[:-1]\n",
    "            data.append((path, desc))\n",
    "    return data\n",
    "\n",
    "\n",
    "img_markup = load_image_markup(\"../data/matching_images.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26effb",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ea826c-7e2b-4039-9782-a63c3a62c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model_name, markup):\n",
    "    model, preprocess_function = clip.load(model_name, device=DEVICE_SETTINGS)\n",
    "\n",
    "    text_list = [markup_line[1].lower() for markup_line in markup]\n",
    "    # some descriptions are the same or mostly same (start from the same words)\n",
    "    unique_indices = []\n",
    "    for idx in range(len(text_list)):\n",
    "        if idx == 0:\n",
    "            unique_indices.append(idx)\n",
    "            continue\n",
    "        prev_started = any(txt.startswith(text_list[idx]) for txt in text_list[:idx])\n",
    "        current_started = any(text_list[idx].startswith(txt) for txt in text_list[:idx])\n",
    "        if prev_started or current_started:\n",
    "            continue\n",
    "        unique_indices.append(idx)\n",
    "    unique_text_list = [text_list[idx] for idx in unique_indices]\n",
    "    unique_text_list_pt = clip.tokenize(unique_text_list).to(DEVICE_SETTINGS)\n",
    "\n",
    "    y_true_list = []\n",
    "    logit_list = []\n",
    "    for img_idx, markup_line in tqdm(enumerate(markup), total=len(text_list)):\n",
    "        with torch.no_grad():\n",
    "            image_pt = preprocess_function(PIL.Image.open(markup_line[0])).unsqueeze(0).to(DEVICE_SETTINGS)\n",
    "\n",
    "            logits_per_image_pt, logits_per_text_pt = model(image_pt, unique_text_list_pt)\n",
    "            # probs = logits_per_image_pt.softmax(dim=-1).cpu().numpy()  # can't be used for not fixed list of variants\n",
    "            logits_per_image = logits_per_image_pt[0].cpu().numpy()\n",
    "            # logits_per_image = 1/(1 + np.exp(-logits_per_image))  # does not work with enough accuracy: all probs are too close to 1\n",
    "\n",
    "        if img_idx not in unique_indices:\n",
    "            assert markup_line[1].lower() == text_list[img_idx]\n",
    "            txt_to_find = markup_line[1].lower()\n",
    "            u_img_idx = -1\n",
    "            for i in range(len(unique_text_list)):\n",
    "                if unique_text_list[i].startswith(txt_to_find) or txt_to_find.startswith(unique_text_list[i]):\n",
    "                    u_img_idx = i\n",
    "                    break\n",
    "            assert u_img_idx >= 0\n",
    "            assert u_img_idx < img_idx\n",
    "        else:\n",
    "            u_img_idx = unique_indices.index(img_idx)\n",
    "\n",
    "        y_true_list += [1 if idx == u_img_idx else 0 for idx in range(len(unique_text_list))]\n",
    "        logit_list += logits_per_image.tolist()\n",
    "\n",
    "    y_true_vec = np.array(y_true_list)\n",
    "    logit_vec = np.array(logit_list)\n",
    "    assert y_true_vec.shape == logit_vec.shape\n",
    "\n",
    "    l_min = logit_vec.min()\n",
    "    l_max = logit_vec.max()\n",
    "    logit_vec = (logit_vec - l_min)/(l_max - l_min)\n",
    "\n",
    "    # https://stats.stackexchange.com/q/287117/\n",
    "    prevalence = np.count_nonzero(y_true_vec == 1, keepdims=False)/len(y_true_vec)\n",
    "    assert prevalence > 0\n",
    "    fpr_vec, tpr_vec, thr_vec = sklearn.metrics.roc_curve(y_true_vec, logit_vec)\n",
    "    recall_vec = tpr_vec\n",
    "    tnr_vec = 1 - fpr_vec\n",
    "\n",
    "    zero_div_idxs = np.where((recall_vec*prevalence) + ((1 - tnr_vec)*(1 - prevalence)) == 0)[0]\n",
    "    if zero_div_idxs.size > 0:\n",
    "        # to avoid zero-division warning from numpy below\n",
    "        recall_vec[zero_div_idxs] += 1e-8\n",
    "    precision_vec = (recall_vec*prevalence)/((recall_vec*prevalence) + ((1 - tnr_vec)*(1 - prevalence)))\n",
    "\n",
    "    zero_div_idxs = np.where(precision_vec + recall_vec == 0)[0]\n",
    "    if zero_div_idxs.size > 0:\n",
    "        # to avoid zero-division warning from numpy below\n",
    "        precision_vec[zero_div_idxs] += 1e-8\n",
    "        recall_vec[zero_div_idxs] += 1e-8\n",
    "    f1_vec = 2*(precision_vec*recall_vec)/(precision_vec + recall_vec)\n",
    "\n",
    "    opt_thr = thr_vec[np.argmax(f1_vec)]\n",
    "    if np.isinf(opt_thr):\n",
    "        opt_thr = 1\n",
    "\n",
    "    # using \">=\" below instead of \">\" is extremely important, because sklearn cn return edge values for threshold\n",
    "    tp = np.count_nonzero((logit_vec >= opt_thr) & (y_true_vec == 1))\n",
    "    fp = np.count_nonzero((logit_vec >= opt_thr) & (y_true_vec == 0))\n",
    "    tn = np.count_nonzero((logit_vec < opt_thr) & (y_true_vec == 0))\n",
    "    fn = np.count_nonzero((logit_vec < opt_thr) & (y_true_vec == 1))\n",
    "\n",
    "    tp_list = [\n",
    "        (logit_list[tp_idx], text_list[tp_idx % len(unique_text_list)])\n",
    "        for tp_idx in np.nonzero((logit_vec >= opt_thr) & (y_true_vec == 1))[0]\n",
    "    ]\n",
    "    tp_list = [(sum(logit for logit, txt in tp_list if txt == u_txt), u_txt) for u_txt in set([txt for logit, txt in tp_list])]\n",
    "    tp_list.sort(key=lambda item: item[0], reverse=True)\n",
    "    fp_list = [\n",
    "        (logit_list[fp_idx], text_list[fp_idx % len(unique_text_list)])\n",
    "        for fp_idx in np.nonzero((logit_vec >= opt_thr) & (y_true_vec == 0))[0]\n",
    "    ]\n",
    "    fp_list = [(sum(logit for logit, txt in fp_list if txt == u_txt), u_txt) for u_txt in set([txt for logit, txt in fp_list])]\n",
    "    fp_list.sort(key=lambda item: item[0], reverse=True)\n",
    "    opt_thr = float(opt_thr)*(l_max - l_min) + l_min\n",
    "\n",
    "    return tp, fp, tn, fn, opt_thr, tp_list, fp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021a6aed-aa05-4485-9e15-1fbd75d62054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ffdbb7b-87d0-4855-82fb-977823e73f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_THRS = {  # these thresholds were picked up manually after brief review of logits, so they are not accurate\n",
    "    \"RN50\": 20,\n",
    "    \"RN101\": 46,\n",
    "    # \"RN50x4\": 36,   # eats too much resources, skipped for full measurements\n",
    "    # \"RN50x16\": 27,  # eats too much resources, skipped for full measurements\n",
    "    # \"RN50x64\": 17,  # eats too much resources, skipped for full measurements\n",
    "    # \"ViT-B/32\": 29,  # eats too much resources, skipped for full measurements\n",
    "    # \"ViT-B/16\": 28,  # eats too much resources, skipped for full measurements\n",
    "    \"ViT-L/14\": 23,\n",
    "    # \"ViT-L/14@336px\": 23,  # eats too much resources, skipped for full measurements\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca24e018-6744-4509-86d2-3e9733fc886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 311/311 [40:27<00:00,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE POSITIVES for RN50:\n",
      "\t(136.8) beige dog\n",
      "\t(107.2) black demi-season ankle boots\n",
      "\t(104.5) baby's ankle boots\n",
      "\t(81.3) women's denim dress with long sleeves\n",
      "\t(81.2) plant in a pot\n",
      "\t(57.3) crib with sides, children's mattress\n",
      "\t(56.9) warm girls' zippered hooded jacket with a floral print\n",
      "\t(56.3) shockproof helmet for babies\n",
      "\t(56.1) glass for hood\n",
      "\t(55.9) pink rubber boots for girls with unicorns, black patent leather shoes for girls, pink summer sandals for girls, burgundy summer shoes\n",
      "\n",
      "\n",
      "FALSE POSITIVES for RN50:\n",
      "\t(25.5) blue jeans\n",
      "\t(25.5) women's shoes top view\n",
      "\t(25.4) women's jeanses blue and black color\n",
      "\t(25.4) women's black leather shoes without heels, women's red shoes with heels\n",
      "\t(25.4) crib with sides, children's mattress\n",
      "\t(25.3) two-door wardrobe with a mezzanine\n",
      "\t(25.2) 3 doors wooden cabinet, armchair, wooden chairs\n",
      "\t(25.2) large pregnancy pillow\n",
      "\t(25.1) geometric patterned floor rug\n",
      "\t(25.1) baby pillow\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 311/311 [40:33<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE POSITIVES for RN101:\n",
      "\t(243.7) black demi-season ankle boots\n",
      "\t(203.7) beige dog\n",
      "\t(156.4) black women's ankle boots with heels, white high-heeled shoes\n",
      "\t(150.6) plant in a pot\n",
      "\t(147.7) women's denim dress with long sleeves\n",
      "\t(103.2) crib with sides, children's mattress\n",
      "\t(102.2) warm girls' zippered hooded jacket with a floral print\n",
      "\t(99.9) refrigerator, wooden kitchen table, stool\n",
      "\t(98.6) baby's ankle boots\n",
      "\t(98.5) iphone case with tom and jerry\n",
      "\n",
      "\n",
      "FALSE POSITIVES for RN101:\n",
      "\t(48.1) black backpack with white print\n",
      "\t(48.1) women's warm down jacket\n",
      "\t(48.1) women's black leather shoes without heels, women's red shoes with heels\n",
      "\t(48.1) a soft toy in the shape of a dog is lying on the sofa\n",
      "\t(48.1) dark gray jacket\n",
      "\t(48.0) pink demi-season women's coat with a fur collar, black zippered jacket, white knitted women's sweater, sand-colored women's pants\n",
      "\t(48.0) women's high-heeled shoes\n",
      "\t(48.0) soft seat for a children's sled\n",
      "\t(47.9) warm girls' zippered hooded jacket with a floral print\n",
      "\t(47.8) a bag of children's toys, a bag of children's safety helmets, a children's magnetic construction set\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 311/311 [1:20:30<00:00, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE POSITIVES for ViT-L/14:\n",
      "\t(172.9) beige dog\n",
      "\t(146.4) black demi-season ankle boots\n",
      "\t(109.7) refrigerator, wooden kitchen table, stool\n",
      "\t(94.7) women's denim dress with long sleeves\n",
      "\t(87.7) peppa pig toysm red toy car, jump rope, minion toy\n",
      "\t(86.1) baby's ankle boots\n",
      "\t(84.0) wheelchair with a black leather seat\n",
      "\t(83.1) plant in a pot\n",
      "\t(62.8) black women's ankle boots with heels, white high-heeled shoes\n",
      "\t(62.4) women's lace-up low shoes\n",
      "\n",
      "\n",
      "FALSE POSITIVES for ViT-L/14:\n",
      "\t(27.5) school backpack for a girl with an owl\n",
      "\t(27.5) bags of cement plaster, paint rollers, plastic buckets\n",
      "\t(27.5) jewelry, braclets\n",
      "\t(27.4) women's black and white checkered jacket, burgundy long sleeve shirt, red t-shirt, white printed t-shirt\n",
      "\t(27.3) children's rocking toy in the shape of a dog\n",
      "\t(27.3) a bag of children's toys, a bag of children's safety helmets, a children's magnetic construction set\n",
      "\t(27.3) baby clothes, blue jumpsuit, striped sleepsuits, knitted red warm jumpsuit\n",
      "\t(27.2) black leather backpack rare view\n",
      "\t(27.2) crib with sides, children's mattress\n",
      "\t(27.1) summer dress for girls with short sleeves and a butterfly print\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_dict = {\"Model\": [], \"TP\": [], \"FP\": [], \"TN\": [], \"FN\": [], \"Threshold\": [], \"Accuracy\": [], \"F1\": []}\n",
    "for model_name, model_thr in MODEL_THRS.items():\n",
    "    tp, fp, tn, fn, thr, tp_list, fp_list = calc_metrics(model_name, img_markup)\n",
    "\n",
    "    if 2*tp + fp + fn > 0:\n",
    "        f1 = 2*tp/(2*tp + fp + fn)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    if tp + fp + tn + fn > 0:\n",
    "        acc = (tp + tn)/(tp + fp + tn + fn)\n",
    "    else:\n",
    "        acc = 0\n",
    "\n",
    "    metric_dict[\"Model\"].append(model_name)\n",
    "    metric_dict[\"TP\"].append(tp)\n",
    "    metric_dict[\"FP\"].append(fp)\n",
    "    metric_dict[\"TN\"].append(tn)\n",
    "    metric_dict[\"FN\"].append(fn)\n",
    "    metric_dict[\"Threshold\"].append(thr)\n",
    "    metric_dict[\"Accuracy\"].append(acc)\n",
    "    metric_dict[\"F1\"].append(f1)\n",
    "\n",
    "    print(f\"TRUE POSITIVES for {model_name}:\\n\\t\" + \"\\n\\t\".join(f\"({logit:.1f}) {txt}\" for logit, txt in tp_list[:10]) + \"\\n\\n\")\n",
    "    print(f\"FALSE POSITIVES for {model_name}:\\n\\t\" + \"\\n\\t\".join(f\"({logit:.1f}) {txt}\" for logit, txt in fp_list[-10:]) + \"\\n\\n\")\n",
    "\n",
    "metric_df = pd.DataFrame(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b35f56-4175-4271-ba33-079437c820d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RN50</td>\n",
       "      <td>126</td>\n",
       "      <td>214</td>\n",
       "      <td>75981</td>\n",
       "      <td>185</td>\n",
       "      <td>25.041956</td>\n",
       "      <td>0.994785</td>\n",
       "      <td>0.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RN101</td>\n",
       "      <td>137</td>\n",
       "      <td>233</td>\n",
       "      <td>75962</td>\n",
       "      <td>174</td>\n",
       "      <td>47.783813</td>\n",
       "      <td>0.994680</td>\n",
       "      <td>0.402349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ViT-L/14</td>\n",
       "      <td>142</td>\n",
       "      <td>217</td>\n",
       "      <td>75978</td>\n",
       "      <td>169</td>\n",
       "      <td>27.141430</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.423881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model   TP   FP     TN   FN  Threshold  Accuracy        F1\n",
       "0      RN50  126  214  75981  185  25.041956  0.994785  0.387097\n",
       "1     RN101  137  233  75962  174  47.783813  0.994680  0.402349\n",
       "2  ViT-L/14  142  217  75978  169  27.141430  0.994955  0.423881"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d93ee-846b-41c2-8c35-36a084101565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
