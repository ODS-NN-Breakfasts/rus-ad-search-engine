{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f30ca-0c7a-4e9a-a5b8-ff293ef4851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(NOTEBOOK_DIR, '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedd87dc-bec1-450d-8d92-1a290b39b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29277fc-9e9c-4e5e-bf7f-68e3a19e9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301b503f-3a02-444b-9d5c-c910e2855296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget\n",
    "# url = 'https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "# wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368ffd0-578b-474a-aeae-d75e83834bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pymorphy3\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from navec import Navec\n",
    "\n",
    "from utils import dataset_utils\n",
    "from utils import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663c530-9dcf-4126-bbbb-b85faa2943db",
   "metadata": {},
   "source": [
    "# Search by word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd883-a975-4be6-bae8-6dbf2a182135",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cf9941-1940-4e1c-bc84-0333f1f4677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUESTS_FILE = \"../data/request_db.txt\"\n",
    "ADS_FILE = \"../data/ads_db.txt\"\n",
    "MATCHING_FILE = \"../data/matching_db.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f51ca95-b069-496f-8806-8716bc2e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ADS_FILE, encoding=\"utf-8\") as f:\n",
    "    ads_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56949b0-0bb4-40f3-a4df-37cee9ff1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(REQUESTS_FILE, encoding=\"utf-8\") as f:\n",
    "    requests_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357b3da0-cecd-4312-8bb8-d78563d1e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_markup = dataset_utils.load_matching_data(MATCHING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28727212-7adb-4ff6-b021-1b7aeaa74c3f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221b8487-d25c-45a4-8506-114a30315b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"\\\\n\", \"\\n\").replace(\"\\n\", \" \")\n",
    "    text = text.strip()\n",
    "    text = text.lower()  # many words have vectors only in lowercase\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "\n",
    "def remove_stop_words(tokens, stop_word_list):\n",
    "    return [tok for tok in tokens if tok not in stop_word_list]\n",
    "\n",
    "\n",
    "def make_normal_forms(morph, tokens):\n",
    "    return [morph.parse(tok)[0].normal_form for tok in tokens]\n",
    "\n",
    "\n",
    "def encode_tokens_to_vectors(navec_model, token_list):\n",
    "    vec_list = []\n",
    "    for tokens in token_list:\n",
    "        vec_list.append([navec_model[tok] for tok in tokens if tok in navec_model])\n",
    "    return vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a67919-c8d7-4f4e-a84b-cadb71b96399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4421a110-7704-4898-abe5-a4a3c85daed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85dbeea3-55aa-48fe-aed5-3bcebf958223",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_stop_words = nltk.corpus.stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45c8da2-f95b-4ba0-97dd-b16a536a6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "705567dc-e034-4907-876c-b0479fb53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_tokens = [make_normal_forms(morph, remove_stop_words(tokenize(preprocess(text)), rus_stop_words)) for text in ads_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ed4aa64-72c6-498a-bacb-5543e799d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_tokens = [make_normal_forms(morph, remove_stop_words(tokenize(preprocess(text)), rus_stop_words)) for text in requests_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f25ad4-c246-413c-a6b1-e79b2c11f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_model = Navec.load(\"navec_hudlit_v1_12B_500K_300d_100q.tar\")\n",
    "# navec_model = Navec.load(\"navec_news_v1_1B_250K_300d_100q.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "253f8f55-46fd-4bd0-b391-1604795374d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ad_tokens = encode_tokens_to_vectors(navec_model, ad_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5e53499-7d36-4e1d-8388-b098f7489df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_req_tokens = encode_tokens_to_vectors(navec_model, req_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcec9e2-fa95-49e3-94c1-ac70bf0fb979",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0701cd74-2739-454c-b72a-b2c42281ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_vectors(enc_req_tok_list, enc_ad_tok_list, threshold):\n",
    "    def cosine_dist(x, y):\n",
    "        return scipy.spatial.distance.cosine(x, y)/2\n",
    "\n",
    "    predictions = {}\n",
    "    for req_id, enc_req_tokens in enumerate(enc_req_tok_list, start=1):\n",
    "        found_list = []\n",
    "        for ad_id, enc_ad_tokens in enumerate(enc_ad_tok_list, start=1):\n",
    "            if len(enc_req_tokens) == 0:\n",
    "                continue\n",
    "            if all(any(cosine_dist(req_tok, ad_tok) <= threshold for ad_tok in enc_ad_tokens) for req_tok in enc_req_tokens):\n",
    "                found_list.append(str(ad_id))\n",
    "        if len(found_list) > 0:\n",
    "            predictions[str(req_id)] = found_list.copy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71f4327b-96f0-4bf4-bca7-3faebbb68cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(enc_req_tok_list, enc_ad_tok_list, dist_type):\n",
    "    def cosine_sim(x, y):\n",
    "        dst = scipy.spatial.distance.cosine(x, y)\n",
    "        assert dst >= 0\n",
    "        assert dst <= 2\n",
    "        return 1 - (dst/2)\n",
    "\n",
    "    def euc_sim(x, y):\n",
    "        dst = np.sqrt(np.sum((x-y)**2))/(np.sqrt(np.sum(x**2)) + np.sqrt(np.sum(y**2)))\n",
    "        assert dst >= 0\n",
    "        assert dst <= 1\n",
    "        return 1 - dst\n",
    "\n",
    "    if dist_type == 'cosine':\n",
    "        sim_func = cosine_sim\n",
    "    elif dist_type == 'euclidean':\n",
    "        sim_func = euc_sim\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distance type: {dist_type}\")\n",
    "\n",
    "    all_probs = []\n",
    "    for enc_req_tokens in enc_req_tok_list:\n",
    "        probs = []\n",
    "        for enc_ad_tokens in enc_ad_tok_list:\n",
    "            probs.append(min([max([sim_func(req_tok, ad_tok) for ad_tok in enc_ad_tokens], default=0) for req_tok in enc_req_tokens], default=0))\n",
    "        all_probs.append(probs.copy())\n",
    "    return np.asarray(all_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ced91-12c8-4f1c-ac41-360d2300edc1",
   "metadata": {},
   "source": [
    "### Tries with Manual Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665f8125-9152-4406-9c25-884c7b619632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_markup = predict_by_vectors(enc_req_tokens, enc_ad_tokens, 0.6)\n",
    "# pred_markup = predict_by_vectors(enc_req_tokens, enc_ad_tokens, 0.25)\n",
    "# pred_markup = predict_by_vectors(enc_req_tokens, enc_ad_tokens, 0.1)\n",
    "pred_markup = predict_by_vectors(enc_req_tokens, enc_ad_tokens, 1 - 0.8551743030548096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70d88008-02ea-4689-98c6-b2167c8450bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 106, 'FP': 128, 'TN': 87100, 'FN': 488}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = metrics.calc_confusion_matrix(true_markup, pred_markup, n_ads=len(ads_raw), n_requests=len(requests_raw))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3aaa536-a1ee-41dd-8fa8-7d30d1f44af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9929858122110633,\n",
       " 'precision': 0.452991452991453,\n",
       " 'recall': 0.17845117845117844,\n",
       " 'f1': 0.2560386473429952}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = metrics.calc_all_stats(confusion_matrix)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83872ea7-2336-44db-a648-ab10741196fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\tMetric\t\t|\tOld Value\t|\tNew Value\t|\tDiff\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tTP\t\t|\t216\t\t|\t106\t\t|\tðŸ“‰ -110\t|\n",
      "|\tFP\t\t|\t418\t\t|\t128\t\t|\tðŸ“‰ -290\t|\n",
      "|\tTN\t\t|\t86810\t\t|\t87100\t\t|\tðŸ“ˆ 290\t|\n",
      "|\tFN\t\t|\t378\t\t|\t488\t\t|\tðŸ“ˆ 110\t|\n",
      "|\tPrec\t\t|\t0.341\t\t|\t0.453\t\t|\tðŸ“ˆ 0.112\t|\n",
      "|\tRecall\t\t|\t0.364\t\t|\t0.178\t\t|\tðŸ“‰ -0.185\t|\n",
      "|\tF1\t\t|\t0.352\t\t|\t0.256\t\t|\tðŸ“‰ -0.096\t|\n",
      "\n",
      "F1 ðŸ“‰ decreased by 0.096, down to 25.6%, which is a significant fall.\n"
     ]
    }
   ],
   "source": [
    "metrics.compare_with_saved_stats(stats, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3740be-fcbd-4d1d-816b-09f549b39fd1",
   "metadata": {},
   "source": [
    "### Tries with Automatic Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d5232-927c-4dd7-a55c-e22b92c80851",
   "metadata": {},
   "source": [
    "#### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1661b1a-eb87-4193-91a4-1f7b4e11d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for cosine distance: 0.8551743030548096\n"
     ]
    }
   ],
   "source": [
    "all_probs = get_probs(enc_req_tokens, enc_ad_tokens, 'cosine')\n",
    "opt_threshold = metrics.calc_optimal_threshold(all_probs, true_markup, len(requests_raw), len(ads_raw))\n",
    "print(f\"Optimal threshold for cosine distance: {opt_threshold}\")\n",
    "pred_markup = metrics.convert_probs_to_markup(all_probs, opt_threshold, len(requests_raw), len(ads_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f88bdcbe-4de7-432e-8b9a-f96b436c8a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 106, 'FP': 128, 'TN': 87100, 'FN': 488}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = metrics.calc_confusion_matrix(true_markup, pred_markup, n_ads=len(ads_raw), n_requests=len(requests_raw))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4acc723f-d483-4dbb-a5c6-752d453339c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9929858122110633,\n",
       " 'precision': 0.452991452991453,\n",
       " 'recall': 0.17845117845117844,\n",
       " 'f1': 0.2560386473429952}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = metrics.calc_all_stats(confusion_matrix)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5d5a289-8b15-4bd3-84b6-bf1b1e7b8992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\tMetric\t\t|\tOld Value\t|\tNew Value\t|\tDiff\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tTP\t\t|\t216\t\t|\t106\t\t|\tðŸ“‰ -110\t|\n",
      "|\tFP\t\t|\t418\t\t|\t128\t\t|\tðŸ“‰ -290\t|\n",
      "|\tTN\t\t|\t86810\t\t|\t87100\t\t|\tðŸ“ˆ 290\t|\n",
      "|\tFN\t\t|\t378\t\t|\t488\t\t|\tðŸ“ˆ 110\t|\n",
      "|\tPrec\t\t|\t0.341\t\t|\t0.453\t\t|\tðŸ“ˆ 0.112\t|\n",
      "|\tRecall\t\t|\t0.364\t\t|\t0.178\t\t|\tðŸ“‰ -0.185\t|\n",
      "|\tF1\t\t|\t0.352\t\t|\t0.256\t\t|\tðŸ“‰ -0.096\t|\n",
      "\n",
      "F1 ðŸ“‰ decreased by 0.096, down to 25.6%, which is a significant fall.\n"
     ]
    }
   ],
   "source": [
    "metrics.compare_with_saved_stats(stats, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b1025-f79b-4346-9500-4d20b27ad688",
   "metadata": {},
   "source": [
    "#### Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57fda9c0-59da-4f45-99bb-604b7aa91cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for euclidean distance: 0.6187620162963867\n"
     ]
    }
   ],
   "source": [
    "all_probs = get_probs(enc_req_tokens, enc_ad_tokens, 'euclidean')\n",
    "opt_threshold = metrics.calc_optimal_threshold(all_probs, true_markup, len(requests_raw), len(ads_raw))\n",
    "print(f\"Optimal threshold for euclidean distance: {opt_threshold}\")\n",
    "pred_markup = metrics.convert_probs_to_markup(all_probs, opt_threshold, len(requests_raw), len(ads_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1ecfd37-1a1e-46a1-b097-e0c8af9c50b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 106, 'FP': 125, 'TN': 87103, 'FN': 488}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = metrics.calc_confusion_matrix(true_markup, pred_markup, n_ads=len(ads_raw), n_requests=len(requests_raw))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70c4c304-b767-45c9-be53-c073c60fd55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9930199722165289,\n",
       " 'precision': 0.4588744588744589,\n",
       " 'recall': 0.17845117845117844,\n",
       " 'f1': 0.25696969696969696}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = metrics.calc_all_stats(confusion_matrix)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dbb246b-5be1-4c30-b13a-db7dcb55392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\tMetric\t\t|\tOld Value\t|\tNew Value\t|\tDiff\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tTP\t\t|\t216\t\t|\t106\t\t|\tðŸ“‰ -110\t|\n",
      "|\tFP\t\t|\t418\t\t|\t125\t\t|\tðŸ“‰ -293\t|\n",
      "|\tTN\t\t|\t86810\t\t|\t87103\t\t|\tðŸ“ˆ 293\t|\n",
      "|\tFN\t\t|\t378\t\t|\t488\t\t|\tðŸ“ˆ 110\t|\n",
      "|\tPrec\t\t|\t0.341\t\t|\t0.459\t\t|\tðŸ“ˆ 0.118\t|\n",
      "|\tRecall\t\t|\t0.364\t\t|\t0.178\t\t|\tðŸ“‰ -0.185\t|\n",
      "|\tF1\t\t|\t0.352\t\t|\t0.257\t\t|\tðŸ“‰ -0.095\t|\n",
      "\n",
      "F1 ðŸ“‰ decreased by 0.095, down to 25.7%, which is a significant fall.\n"
     ]
    }
   ],
   "source": [
    "metrics.compare_with_saved_stats(stats, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee31d1-210b-461a-bfae-ec97e37321f7",
   "metadata": {},
   "source": [
    "## Requests with no vectors\n",
    "\n",
    "Maybe, the reason of low accuracy is requests that have no word embeddings? There are words with intentionally added typos and just usual OOV words. Words with typos won't work even for direct matching, so we should consider only OOV words. Let's calculate decrease in `TP` due to OOV words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4882806-2696-477a-b12d-ae46b914a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words without embeddings:\n",
      "-30\n",
      ".\n",
      "1\n",
      "12\n",
      "160ÑÐ¼\n",
      "3\n",
      "30ÑÐ¼\n",
      "38\n",
      "42\n",
      "45Ðº\n",
      "48\n",
      "5\n",
      "50-52\n",
      "5Ð¼\n",
      "6\n",
      "64\n",
      "68-74\n",
      "7\n",
      "Ð°Ð²Ñ‚Ð¾ÐºÑ€ÐµÑÐ»Ð¾\n",
      "Ð°Ð²Ñ‚Ð¾Ð»ÑŽÐ»ÑŒÐºÐ°\n",
      "Ð°ÐºÑÑÐµÑÑƒÐ°Ñ€\n",
      "Ð±ÐµÐ³Ð¾Ð²ÐµÑ‚ÑŒ\n",
      "Ð±ÐµÐ·ÑÐ°Ñ…Ð°Ñ€\n",
      "Ð±Ð¾Ð»ÑŒÑˆÑˆÐ°\n",
      "Ð²ÐµÐ¹Ð¿\n",
      "Ð²ÐµÐ»Ð¾Ñ‚Ñ€ÐµÐ½Ð°Ð¶Ñ‘Ñ€\n",
      "Ð²ÐµÑÐ½Ð°-Ð¾ÑÐµÐ½ÑŒ\n",
      "Ð´ÐµÐ¼Ð¸-ÑÐµÐ·Ð¾Ð½\n",
      "Ð´ÐµÐ¼Ð¸ÑÐµÐ·Ð¾Ð½\n",
      "Ð´ÐµÐ¼Ð¸ÑÐµÐ·Ð¾Ð½Ð½Ñ‹Ð¹\n",
      "Ð´ÐµÑ‰ÐµÐ²Ð¾\n",
      "Ð´ÐºÐ°Ñ€Ð°Ð½ÑÑ‚ÑŒ\n",
      "Ð´Ñ€Ð°Ð¿Ð¾Ð²Ñ‹Ð¹\n",
      "Ð¶ÐµÑÐºÐ¸Ð¹\n",
      "Ð·ÐµÑ€ÐºÐ°Ð»ÐºÐ°\n",
      "Ð·Ð¸Ð¼Ð°-Ð¾ÑÐµÐ½ÑŒ\n",
      "Ð¸ÐºÐµÑ\n",
      "Ð¸ÑÐºÑƒÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹\n",
      "ÐºÐ°ÑÑ‚ÑŽÐ¼\n",
      "ÐºÐ»Ð¸Ð½Ð¸Ð½Ð³Ð°\n",
      "ÐºÐ¾Ð¶Ð·Ð°Ð¼\n",
      "ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð·Ð¾Ð½\n",
      "ÐºÐ¾Ð¼ÐµÑ‚Ð¸Ðº\n",
      "ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹-Ð¿Ñ€Ð¸Ñ‚Ð°Ð»ÐµÐ½Ð½Ñ‹Ð¹\n",
      "ÐºÐ¾Ñ‚Ð¾Ð½ÑÐ½Ñ\n",
      "ÐºÑ€ÑƒÑÐ»Ð¾\n",
      "ÐºÑ€ÑƒÑ‚ÐºÐ°\n",
      "Ð¼Ð¾Ñ‰ÑŒÐ½Ñ‹Ð¹\n",
      "Ð¾Ð²ÐµÑ€ÑÐ°Ð¹Ð·Ð°\n",
      "Ð¾Ð³Ñ\n",
      "Ð¾Ð´Ð½Ð¾ÑÐ¿Ð°Ð»ÑŒÐ½Ñ‹Ð¹\n",
      "Ð¾Ð½Ñ‚Ð¾Ð½Ð¾Ð²ÐºÐ°\n",
      "Ð¾Ð¿Ð¸Ð»ÐºÐ°\n",
      "Ð¿Ð°Ð»ÑŒÑ‚Ð¾-ÐºÑƒÑ€Ñ‚ÐºÐ°\n",
      "Ð¿Ð¾-Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼Ñƒ\n",
      "Ð¿Ñ€Ð¸Ñ‚Ð°Ð»Ñ‘Ð½Ñ‹Ð¹\n",
      "Ñ€Ð°ÑÐ¿Ð°ÑˆÐµÐ½ÐºÐ°\n",
      "Ñ€Ð°ÑÑÑ‚ÑƒÑ‰Ð¸Ð¹\n",
      "Ñ€Ð¾Ñ‚Ð°Ð½Ð³\n",
      "ÑÐ°Ð¹Ð·Ð°\n",
      "ÑÐ°Ð¼Ð¾Ð²Ñ‹Ð²Ð¾Ð·\n",
      "ÑÐ°Ð¼Ð¾ÑÐ±Ð¾Ñ€\n",
      "ÑÐ°Ð½Ð´Ð°Ð»Ð¸\n",
      "ÑÐ½ÑƒÐ´Ð°\n",
      "ÑÐ¾Ð²ÐµÑÑ‚ÐºÐ¸Ð¹\n",
      "ÑÐ¾Ñ†Ð³Ð¾Ñ€Ð¾Ð´\n",
      "ÑÑƒÐ¼ÐºÐ°-ÑˆÐ¾Ð¿ÐµÑ€\n",
      "ÑÑƒÑˆÑ‘Ð½Ñ‹Ð¹\n",
      "Ñ‚ÐµÐ»Ð¿Ñ‹Ð¹\n",
      "Ñ‚ÑƒÑ„Ð¸Ð»ÑŒÐºÐ°\n",
      "ÑƒÑ…Ð¾Ð´Ð¾Ð²Ð¾Ð¹\n",
      "Ñ„Ð¾Ñ‚Ð¾ÑÑ‚ÑƒÐ´Ð¸Ñ\n",
      "Ñ‡ÐµÑ€Ð¼ÐµÑ‚Ð°\n",
      "ÑˆÐ¸Ñ„Ð¾Ð½Ñ‘Ñ€\n",
      "ÑˆÐ¾Ñ‚Ñ€\n",
      "ÑÐºÐ¾ÐºÐ¾Ð¶Ð°\n",
      "ÑÐºÐ¾Ð¼ÐµÑˆÐ¾Ñ‡ÐµÐº\n",
      "ÑÐ»ÐµÐºÑ‚Ñ€Ð¾ÑÐ°Ð¼Ð¾ÐºÐ°Ñ‚\n"
     ]
    }
   ],
   "source": [
    "not_found_words = []\n",
    "for req_tok_list in req_tokens:\n",
    "    for tok in req_tok_list:\n",
    "        try:\n",
    "            navec_model[tok]\n",
    "        except KeyError:\n",
    "            not_found_words.append(tok)\n",
    "print(\"Words without embeddings:\\n\" + \"\\n\".join(sorted(set(not_found_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52087266-047b-4988-b528-db8b21a59f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers were also skipped, since we don't expect they appear in the advertisements\n",
    "real_oov_words = [\n",
    "    \"Ð°Ð²Ñ‚Ð¾ÐºÑ€ÐµÑÐ»Ð¾\", \"Ð°Ð²Ñ‚Ð¾Ð»ÑŽÐ»ÑŒÐºÐ°\", \"Ð°ÐºÑÑÐµÑÑƒÐ°Ñ€\", \"Ð±ÐµÐ³Ð¾Ð²ÐµÑ‚ÑŒ\", \"Ð±ÐµÐ·ÑÐ°Ñ…Ð°Ñ€\", \"Ð±Ð¾Ð»ÑŒÑˆÑˆÐ°\", \"Ð²ÐµÐ¹Ð¿\", \"Ð²ÐµÐ»Ð¾Ñ‚Ñ€ÐµÐ½Ð°Ð¶Ñ‘Ñ€\", \"Ð²ÐµÑÐ½Ð°-Ð¾ÑÐµÐ½ÑŒ\", \"Ð´ÐµÐ¼Ð¸-ÑÐµÐ·Ð¾Ð½\",\n",
    "    \"Ð´ÐµÐ¼Ð¸ÑÐµÐ·Ð¾Ð½\", \"Ð´ÐµÐ¼Ð¸ÑÐµÐ·Ð¾Ð½Ð½Ñ‹Ð¹\", \"Ð´ÐµÑ‰ÐµÐ²Ð¾\", \"Ð´ÐºÐ°Ñ€Ð°Ð½ÑÑ‚ÑŒ\", \"Ð´Ñ€Ð°Ð¿Ð¾Ð²Ñ‹Ð¹\", \"Ð¶ÐµÑÐºÐ¸Ð¹\",\n",
    "    \"Ð·ÐµÑ€ÐºÐ°Ð»ÐºÐ°\", \"Ð·Ð¸Ð¼Ð°-Ð¾ÑÐµÐ½ÑŒ\", \"Ð¸ÐºÐµÑ\", \"Ð¸ÑÐºÑƒÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹\", \"ÐºÐ°ÑÑ‚ÑŽÐ¼\", \"ÐºÐ»Ð¸Ð½Ð¸Ð½Ð³Ð°\", \"ÐºÐ¾Ð¶Ð·Ð°Ð¼\", \"ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð·Ð¾Ð½\", \"ÐºÐ¾Ð¼ÐµÑ‚Ð¸Ðº\", \"ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹-Ð¿Ñ€Ð¸Ñ‚Ð°Ð»ÐµÐ½Ð½Ñ‹Ð¹\", \"ÐºÐ¾Ñ‚Ð¾Ð½ÑÐ½Ñ\", \n",
    "    \"ÐºÑ€ÑƒÑÐ»Ð¾\", \"ÐºÑ€ÑƒÑ‚ÐºÐ°\", \"Ð¼Ð¾Ñ‰ÑŒÐ½Ñ‹Ð¹\", \"Ð¾Ð²ÐµÑ€ÑÐ°Ð¹Ð·Ð°\", \"Ð¾Ð³Ñ\", \"Ð¾Ð´Ð½Ð¾ÑÐ¿Ð°Ð»ÑŒÐ½Ñ‹Ð¹\", \"Ð¾Ð½Ñ‚Ð¾Ð½Ð¾Ð²ÐºÐ°\",\n",
    "    \"Ð¾Ð¿Ð¸Ð»ÐºÐ°\", \"Ð¿Ð°Ð»ÑŒÑ‚Ð¾-ÐºÑƒÑ€Ñ‚ÐºÐ°\", \"Ð¿Ð¾-Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼Ñƒ\", \"Ð¿Ñ€Ð¸Ñ‚Ð°Ð»Ñ‘Ð½Ñ‹Ð¹\", \"Ñ€Ð°ÑÐ¿Ð°ÑˆÐµÐ½ÐºÐ°\", \"Ñ€Ð°ÑÑÑ‚ÑƒÑ‰Ð¸Ð¹\", \"Ñ€Ð¾Ñ‚Ð°Ð½Ð³\", \n",
    "    \"ÑÐ°Ð¹Ð·Ð°\", \"ÑÐ°Ð¼Ð¾Ð²Ñ‹Ð²Ð¾Ð·\", \"ÑÐ°Ð¼Ð¾ÑÐ±Ð¾Ñ€\", \"ÑÐ°Ð½Ð´Ð°Ð»Ð¸\", \"ÑÐ½ÑƒÐ´Ð°\",\"ÑÐ¾Ð²ÐµÑÑ‚ÐºÐ¸Ð¹\", \"ÑÐ¾Ñ†Ð³Ð¾Ñ€Ð¾Ð´\", \"ÑÑƒÑˆÑ‘Ð½Ñ‹Ð¹\", \"ÑÑƒÐ¼ÐºÐ°-ÑˆÐ¾Ð¿ÐµÑ€\", \"Ñ‚ÐµÐ»Ð¿Ñ‹Ð¹\", \"Ñ‚ÑƒÑ„Ð¸Ð»ÑŒÐºÐ°\", \"ÑƒÑ…Ð¾Ð´Ð¾Ð²Ð¾Ð¹\",\n",
    "    \"Ñ„Ð¾Ñ‚Ð¾ÑÑ‚ÑƒÐ´Ð¸Ñ\", \"Ñ‡ÐµÑ€Ð¼ÐµÑ‚Ð°\", \"ÑˆÐ¸Ñ„Ð¾Ð½Ñ‘Ñ€\", \"ÑˆÐ¾Ñ‚Ñ€\", \"ÑÐºÐ¾ÐºÐ¾Ð¶Ð°\", \"ÑÐºÐ¾Ð¼ÐµÑˆÐ¾Ñ‡ÐµÐº\", \"ÑÐ»ÐµÐºÑ‚Ñ€Ð¾ÑÐ°Ð¼Ð¾ÐºÐ°Ñ‚\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "797086a4-6893-445c-afa9-b1b7a1c4792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed TPs: 7\n",
      "New value for F1 would be 26.8%, comparing with 25.6% for cosine distance\n"
     ]
    }
   ],
   "source": [
    "missed_tps = 0\n",
    "for req_id, req_tok_list in enumerate(req_tokens, start=1):\n",
    "    if any(tok in real_oov_words for tok in req_tok_list) and str(req_id) in true_markup:\n",
    "        missed_tps += sum(\n",
    "            1 if all(req_tok in ad_tokens[int(ad_id) - 1] for req_tok in req_tok_list) else 0 for ad_id in true_markup[str(req_id)]\n",
    "        )\n",
    "print(f\"Missed TPs: {missed_tps}\")\n",
    "\n",
    "# comparing with cosine distance, for example\n",
    "new_tp = 106 + missed_tps\n",
    "new_fp = 128\n",
    "new_tn = 87100 - missed_tps\n",
    "new_fn = 488\n",
    "print(f\"New value for F1 would be {100*(2*(new_tp)/((2*new_tp) + new_fp + new_fn)):.1f}%, comparing with 25.6% for cosine distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475feb52-e6d7-48c0-b665-99105a53261b",
   "metadata": {},
   "source": [
    "So it looks like NaVec vectors don't help mainly because of lots of false positives, not only because of OOV words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ed8a8-ac32-4eda-b571-6a1b4d055bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
